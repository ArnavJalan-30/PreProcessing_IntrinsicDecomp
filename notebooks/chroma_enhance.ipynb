{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6ccf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\COLLEGE MATERIAL\\Ordinal_Shading\n"
     ]
    }
   ],
   "source": [
    "%cd E:\\COLLEGE MATERIAL\\Ordinal_Shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86bdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c960d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Ensure local imports work\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "\n",
    "from chrislib.general import view, invert\n",
    "from chrislib.data_util import load_image\n",
    "from intrinsic.pipeline import run_pipeline\n",
    "from altered_midas.midas_net import MidasNet\n",
    "from altered_midas.midas_net_custom import MidasNet_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ce6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading models manually from local weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models loaded\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------\n",
    "# MANUAL MODEL LOADING (local weights)\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¦ Loading models manually from local weights...\")\n",
    "model_dir = \"models\"\n",
    "ord_model = MidasNet()\n",
    "ord_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_0_v21.pt\"), map_location=device))\n",
    "ord_model.eval()\n",
    "ord_model = ord_model.to(device)\n",
    "\n",
    "iid_model = MidasNet_small(exportable=False, input_channels=5, output_channels=1)\n",
    "iid_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_1_v21.pt\"), map_location=device))\n",
    "iid_model.eval()\n",
    "iid_model = iid_model.to(device)\n",
    "\n",
    "col_model = MidasNet(activation='sigmoid', input_channels=7, output_channels=2)\n",
    "col_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_2_v21.pt\"), map_location=device))\n",
    "col_model.eval()\n",
    "col_model = col_model.to(device)\n",
    "\n",
    "alb_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3, last_residual=True)\n",
    "alb_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_3_v21.pt\"), map_location=device))\n",
    "alb_model.eval()\n",
    "alb_model = alb_model.to(device)\n",
    "\n",
    "dif_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3)\n",
    "dif_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_4_v21.pt\"), map_location=device))\n",
    "dif_model.eval()\n",
    "dif_model = dif_model.to(device)\n",
    "\n",
    "models = {\n",
    "    \"ord_model\": ord_model,\n",
    "    \"iid_model\": iid_model,\n",
    "    \"col_model\": col_model,\n",
    "    \"alb_model\": alb_model,\n",
    "    \"dif_model\": dif_model,\n",
    "}\n",
    "print(\"âœ… Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861e9161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [05:08<00:00, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your ARAP dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dd154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\chroma_enhance_input\n",
      "Processing first 200 images in numeric order\n",
      "Numeric processing order preview (first 15): ['54', '63', '116', '119', '141', '176', '180', '182', '227', '239', '245', '253', '257', '262', '277']\n",
      "Image 1/200 (54) | Time/iter: 11.54s | ETA: 00:38:17\n",
      "Image 2/200 (63) | Time/iter: 5.57s | ETA: 00:18:21\n",
      "Image 3/200 (116) | Time/iter: 4.92s | ETA: 00:16:09\n",
      "Image 4/200 (119) | Time/iter: 5.61s | ETA: 00:18:20\n",
      "Image 5/200 (141) | Time/iter: 5.37s | ETA: 00:17:26\n",
      "Image 6/200 (176) | Time/iter: 5.42s | ETA: 00:17:30\n",
      "Image 7/200 (180) | Time/iter: 4.79s | ETA: 00:15:24\n",
      "Image 8/200 (182) | Time/iter: 4.97s | ETA: 00:15:54\n",
      "Image 9/200 (227) | Time/iter: 4.07s | ETA: 00:12:57\n",
      "Image 10/200 (239) | Time/iter: 7.56s | ETA: 00:23:57\n",
      "Image 11/200 (245) | Time/iter: 4.71s | ETA: 00:14:49\n",
      "Image 12/200 (253) | Time/iter: 4.39s | ETA: 00:13:45\n",
      "Image 13/200 (257) | Time/iter: 3.89s | ETA: 00:12:08\n",
      "Image 14/200 (262) | Time/iter: 3.78s | ETA: 00:11:42\n",
      "Image 15/200 (277) | Time/iter: 10.56s | ETA: 00:32:33\n",
      "Image 16/200 (370) | Time/iter: 7.00s | ETA: 00:21:28\n",
      "Image 17/200 (417) | Time/iter: 6.95s | ETA: 00:21:11\n",
      "Image 18/200 (434) | Time/iter: 10.20s | ETA: 00:30:56\n",
      "Image 19/200 (491) | Time/iter: 10.40s | ETA: 00:31:22\n",
      "Image 20/200 (498) | Time/iter: 4.49s | ETA: 00:13:28\n",
      "Image 21/200 (502) | Time/iter: 3.95s | ETA: 00:11:46\n",
      "Image 22/200 (504) | Time/iter: 9.21s | ETA: 00:27:20\n",
      "Image 23/200 (527) | Time/iter: 4.94s | ETA: 00:14:34\n",
      "Image 24/200 (560) | Time/iter: 5.54s | ETA: 00:16:15\n",
      "Image 25/200 (579) | Time/iter: 5.42s | ETA: 00:15:47\n",
      "Image 26/200 (593) | Time/iter: 6.86s | ETA: 00:19:53\n",
      "Image 27/200 (594) | Time/iter: 4.85s | ETA: 00:13:59\n",
      "Image 28/200 (597) | Time/iter: 4.93s | ETA: 00:14:07\n",
      "Image 29/200 (611) | Time/iter: 5.06s | ETA: 00:14:25\n",
      "Image 30/200 (613) | Time/iter: 6.57s | ETA: 00:18:37\n",
      "Image 31/200 (627) | Time/iter: 5.02s | ETA: 00:14:09\n",
      "Image 32/200 (633) | Time/iter: 4.87s | ETA: 00:13:38\n",
      "Image 33/200 (653) | Time/iter: 4.89s | ETA: 00:13:36\n",
      "Image 34/200 (657) | Time/iter: 5.14s | ETA: 00:14:13\n",
      "Image 35/200 (662) | Time/iter: 5.72s | ETA: 00:15:43\n",
      "Image 36/200 (686) | Time/iter: 4.74s | ETA: 00:12:56\n",
      "Image 37/200 (749) | Time/iter: 4.40s | ETA: 00:11:57\n",
      "Image 38/200 (760) | Time/iter: 3.82s | ETA: 00:10:19\n",
      "Image 39/200 (771) | Time/iter: 4.32s | ETA: 00:11:35\n",
      "Image 40/200 (791) | Time/iter: 3.75s | ETA: 00:10:00\n",
      "Image 41/200 (815) | Time/iter: 3.99s | ETA: 00:10:33\n",
      "Image 42/200 (821) | Time/iter: 3.93s | ETA: 00:10:21\n",
      "Image 43/200 (827) | Time/iter: 4.37s | ETA: 00:11:25\n",
      "Image 44/200 (844) | Time/iter: 4.44s | ETA: 00:11:32\n",
      "Image 45/200 (845) | Time/iter: 4.22s | ETA: 00:10:54\n",
      "Image 46/200 (856) | Time/iter: 3.75s | ETA: 00:09:36\n",
      "Image 47/200 (859) | Time/iter: 3.75s | ETA: 00:09:33\n",
      "Image 48/200 (860) | Time/iter: 4.33s | ETA: 00:10:58\n",
      "Image 49/200 (876) | Time/iter: 10.37s | ETA: 00:26:06\n",
      "Image 50/200 (918) | Time/iter: 3.80s | ETA: 00:09:30\n",
      "Image 51/200 (922) | Time/iter: 4.20s | ETA: 00:10:26\n",
      "Image 52/200 (952) | Time/iter: 6.88s | ETA: 00:16:57\n",
      "Image 53/200 (953) | Time/iter: 4.28s | ETA: 00:10:29\n",
      "Image 54/200 (1014) | Time/iter: 11.92s | ETA: 00:29:00\n",
      "Image 55/200 (1068) | Time/iter: 3.78s | ETA: 00:09:07\n",
      "Image 56/200 (1094) | Time/iter: 4.34s | ETA: 00:10:25\n",
      "Image 57/200 (1118) | Time/iter: 4.38s | ETA: 00:10:26\n",
      "Image 58/200 (1127) | Time/iter: 6.95s | ETA: 00:16:27\n",
      "Image 59/200 (1141) | Time/iter: 4.47s | ETA: 00:10:30\n",
      "Image 60/200 (1143) | Time/iter: 4.04s | ETA: 00:09:25\n",
      "Image 61/200 (1195) | Time/iter: 3.72s | ETA: 00:08:37\n",
      "Image 62/200 (1206) | Time/iter: 3.69s | ETA: 00:08:29\n",
      "Image 63/200 (1221) | Time/iter: 4.20s | ETA: 00:09:36\n",
      "Image 64/200 (1226) | Time/iter: 6.75s | ETA: 00:15:17\n",
      "Image 65/200 (1232) | Time/iter: 3.92s | ETA: 00:08:49\n",
      "Image 66/200 (1245) | Time/iter: 4.18s | ETA: 00:09:20\n",
      "Image 67/200 (1302) | Time/iter: 4.26s | ETA: 00:09:26\n",
      "Image 68/200 (1376) | Time/iter: 3.70s | ETA: 00:08:08\n",
      "Image 69/200 (1453) | Time/iter: 3.80s | ETA: 00:08:17\n",
      "Image 70/200 (1694) | Time/iter: 3.71s | ETA: 00:08:02\n",
      "Image 71/200 (1934) | Time/iter: 3.71s | ETA: 00:07:58\n",
      "Image 72/200 (2066) | Time/iter: 3.76s | ETA: 00:08:01\n",
      "Image 73/200 (2200) | Time/iter: 4.15s | ETA: 00:08:47\n",
      "Image 74/200 (2232) | Time/iter: 3.53s | ETA: 00:07:24\n",
      "Image 75/200 (2237) | Time/iter: 17.98s | ETA: 00:37:27\n",
      "Image 76/200 (2254) | Time/iter: 3.76s | ETA: 00:07:45\n",
      "Image 77/200 (2301) | Time/iter: 4.48s | ETA: 00:09:11\n",
      "Image 78/200 (2305) | Time/iter: 4.37s | ETA: 00:08:53\n",
      "Image 79/200 (2311) | Time/iter: 4.14s | ETA: 00:08:20\n",
      "Image 80/200 (2324) | Time/iter: 4.19s | ETA: 00:08:23\n",
      "Image 81/200 (2349) | Time/iter: 14.07s | ETA: 00:27:54\n",
      "Image 82/200 (2352) | Time/iter: 4.02s | ETA: 00:07:54\n",
      "Image 83/200 (2355) | Time/iter: 3.86s | ETA: 00:07:32\n",
      "Image 84/200 (2377) | Time/iter: 4.00s | ETA: 00:07:43\n",
      "Image 85/200 (2406) | Time/iter: 3.67s | ETA: 00:07:02\n",
      "Image 86/200 (2466) | Time/iter: 3.73s | ETA: 00:07:04\n",
      "Image 87/200 (2471) | Time/iter: 4.15s | ETA: 00:07:48\n",
      "Image 88/200 (2476) | Time/iter: 3.76s | ETA: 00:07:01\n",
      "Image 89/200 (2504) | Time/iter: 7.76s | ETA: 00:14:21\n",
      "Image 90/200 (2545) | Time/iter: 3.88s | ETA: 00:07:06\n",
      "Image 91/200 (2547) | Time/iter: 7.01s | ETA: 00:12:43\n",
      "Image 92/200 (2548) | Time/iter: 11.24s | ETA: 00:20:13\n",
      "Image 93/200 (2598) | Time/iter: 4.15s | ETA: 00:07:24\n",
      "Image 94/200 (2602) | Time/iter: 4.70s | ETA: 00:08:18\n",
      "Image 95/200 (2606) | Time/iter: 3.90s | ETA: 00:06:49\n",
      "Image 96/200 (2615) | Time/iter: 4.46s | ETA: 00:07:43\n",
      "Image 97/200 (2620) | Time/iter: 4.39s | ETA: 00:07:32\n",
      "Image 98/200 (2636) | Time/iter: 4.36s | ETA: 00:07:25\n",
      "Image 99/200 (2715) | Time/iter: 10.78s | ETA: 00:18:08\n",
      "Image 100/200 (2727) | Time/iter: 4.51s | ETA: 00:07:31\n",
      "Image 101/200 (2758) | Time/iter: 3.92s | ETA: 00:06:27\n",
      "Image 102/200 (2789) | Time/iter: 3.92s | ETA: 00:06:24\n",
      "Image 103/200 (2828) | Time/iter: 4.37s | ETA: 00:07:04\n",
      "Image 104/200 (2894) | Time/iter: 7.15s | ETA: 00:11:26\n",
      "Image 105/200 (2910) | Time/iter: 7.55s | ETA: 00:11:57\n",
      "Image 106/200 (2970) | Time/iter: 7.26s | ETA: 00:11:22\n",
      "Image 107/200 (2998) | Time/iter: 7.20s | ETA: 00:11:09\n",
      "Image 108/200 (3044) | Time/iter: 7.23s | ETA: 00:11:05\n",
      "Image 109/200 (3072) | Time/iter: 4.03s | ETA: 00:06:06\n",
      "Image 110/200 (3136) | Time/iter: 11.06s | ETA: 00:16:35\n",
      "Image 111/200 (3199) | Time/iter: 4.06s | ETA: 00:06:01\n",
      "Image 112/200 (3219) | Time/iter: 3.88s | ETA: 00:05:41\n",
      "Image 113/200 (3221) | Time/iter: 3.89s | ETA: 00:05:38\n",
      "Image 114/200 (3240) | Time/iter: 4.19s | ETA: 00:06:00\n",
      "Image 115/200 (3246) | Time/iter: 4.31s | ETA: 00:06:06\n",
      "Image 116/200 (3247) | Time/iter: 7.39s | ETA: 00:10:20\n",
      "Image 117/200 (3254) | Time/iter: 7.16s | ETA: 00:09:54\n",
      "Image 118/200 (3305) | Time/iter: 7.20s | ETA: 00:09:50\n",
      "Image 119/200 (3308) | Time/iter: 5.18s | ETA: 00:06:59\n",
      "Image 120/200 (3353) | Time/iter: 4.43s | ETA: 00:05:54\n",
      "Image 121/200 (3363) | Time/iter: 5.39s | ETA: 00:07:05\n",
      "Image 122/200 (3392) | Time/iter: 4.24s | ETA: 00:05:30\n",
      "Image 123/200 (3400) | Time/iter: 3.54s | ETA: 00:04:32\n",
      "Image 124/200 (3403) | Time/iter: 6.77s | ETA: 00:08:34\n",
      "Image 125/200 (3438) | Time/iter: 3.77s | ETA: 00:04:42\n",
      "Image 126/200 (3446) | Time/iter: 7.10s | ETA: 00:08:45\n",
      "Image 127/200 (3463) | Time/iter: 6.97s | ETA: 00:08:28\n",
      "Image 128/200 (3466) | Time/iter: 7.46s | ETA: 00:08:56\n",
      "Image 129/200 (3544) | Time/iter: 10.58s | ETA: 00:12:31\n",
      "Image 130/200 (3592) | Time/iter: 4.47s | ETA: 00:05:12\n",
      "Image 131/200 (3625) | Time/iter: 4.20s | ETA: 00:04:50\n",
      "Image 132/200 (3642) | Time/iter: 4.28s | ETA: 00:04:51\n",
      "Image 133/200 (3679) | Time/iter: 4.63s | ETA: 00:05:10\n",
      "Image 134/200 (3701) | Time/iter: 6.81s | ETA: 00:07:29\n",
      "Image 135/200 (3715) | Time/iter: 6.89s | ETA: 00:07:28\n",
      "Image 136/200 (3730) | Time/iter: 4.52s | ETA: 00:04:49\n",
      "Image 137/200 (3773) | Time/iter: 3.60s | ETA: 00:03:46\n",
      "Image 138/200 (3859) | Time/iter: 6.86s | ETA: 00:07:05\n",
      "Image 139/200 (3864) | Time/iter: 4.17s | ETA: 00:04:14\n",
      "Image 140/200 (3877) | Time/iter: 3.79s | ETA: 00:03:47\n",
      "Image 141/200 (3916) | Time/iter: 6.90s | ETA: 00:06:47\n",
      "Image 142/200 (3932) | Time/iter: 4.47s | ETA: 00:04:19\n",
      "Image 143/200 (3958) | Time/iter: 7.60s | ETA: 00:07:13\n",
      "Image 144/200 (4023) | Time/iter: 6.97s | ETA: 00:06:30\n",
      "Image 145/200 (4032) | Time/iter: 3.79s | ETA: 00:03:28\n",
      "Image 146/200 (4037) | Time/iter: 3.70s | ETA: 00:03:19\n",
      "Image 147/200 (4057) | Time/iter: 4.27s | ETA: 00:03:46\n",
      "Image 148/200 (4131) | Time/iter: 3.94s | ETA: 00:03:24\n",
      "Image 149/200 (4136) | Time/iter: 4.38s | ETA: 00:03:43\n",
      "Image 150/200 (4203) | Time/iter: 4.00s | ETA: 00:03:19\n",
      "Image 151/200 (4217) | Time/iter: 18.00s | ETA: 00:14:41\n",
      "Image 152/200 (4259) | Time/iter: 21.69s | ETA: 00:17:21\n",
      "Image 153/200 (4264) | Time/iter: 4.28s | ETA: 00:03:21\n",
      "Image 154/200 (4269) | Time/iter: 14.68s | ETA: 00:11:15\n",
      "Image 155/200 (4287) | Time/iter: 3.76s | ETA: 00:02:49\n",
      "Image 156/200 (4302) | Time/iter: 6.81s | ETA: 00:04:59\n",
      "Image 157/200 (4392) | Time/iter: 3.80s | ETA: 00:02:43\n",
      "Image 158/200 (4440) | Time/iter: 3.75s | ETA: 00:02:37\n",
      "Image 159/200 (4495) | Time/iter: 10.29s | ETA: 00:07:01\n",
      "Image 160/200 (4496) | Time/iter: 3.90s | ETA: 00:02:36\n",
      "Image 161/200 (4542) | Time/iter: 3.90s | ETA: 00:02:32\n",
      "Image 162/200 (4574) | Time/iter: 4.51s | ETA: 00:02:51\n",
      "Image 163/200 (4593) | Time/iter: 15.23s | ETA: 00:09:23\n",
      "Image 164/200 (4627) | Time/iter: 4.54s | ETA: 00:02:43\n",
      "Image 165/200 (4687) | Time/iter: 7.88s | ETA: 00:04:35\n",
      "Image 166/200 (4746) | Time/iter: 4.18s | ETA: 00:02:22\n",
      "Image 167/200 (4767) | Time/iter: 3.93s | ETA: 00:02:09\n",
      "Image 168/200 (4788) | Time/iter: 5.34s | ETA: 00:02:50\n",
      "Image 169/200 (4796) | Time/iter: 11.02s | ETA: 00:05:41\n",
      "Image 170/200 (4823) | Time/iter: 10.54s | ETA: 00:05:16\n",
      "Image 171/200 (4825) | Time/iter: 4.82s | ETA: 00:02:19\n",
      "Image 172/200 (4856) | Time/iter: 4.61s | ETA: 00:02:09\n",
      "Image 173/200 (4934) | Time/iter: 4.46s | ETA: 00:02:00\n",
      "Image 174/200 (4991) | Time/iter: 4.20s | ETA: 00:01:49\n",
      "Image 175/200 (5049) | Time/iter: 4.20s | ETA: 00:01:45\n",
      "Image 176/200 (5059) | Time/iter: 7.37s | ETA: 00:02:56\n",
      "Image 177/200 (5062) | Time/iter: 4.59s | ETA: 00:01:45\n",
      "Image 178/200 (5214) | Time/iter: 11.07s | ETA: 00:04:03\n",
      "Image 179/200 (5234) | Time/iter: 7.53s | ETA: 00:02:38\n",
      "Image 180/200 (5249) | Time/iter: 15.32s | ETA: 00:05:06\n",
      "Image 181/200 (5253) | Time/iter: 7.71s | ETA: 00:02:26\n",
      "Image 182/200 (5254) | Time/iter: 12.22s | ETA: 00:03:39\n",
      "Image 183/200 (5285) | Time/iter: 5.13s | ETA: 00:01:27\n",
      "Image 184/200 (5360) | Time/iter: 4.13s | ETA: 00:01:06\n",
      "Image 185/200 (5382) | Time/iter: 4.60s | ETA: 00:01:09\n",
      "Image 186/200 (5383) | Time/iter: 7.42s | ETA: 00:01:43\n",
      "Image 187/200 (5460) | Time/iter: 4.09s | ETA: 00:00:53\n",
      "Image 188/200 (5568) | Time/iter: 3.87s | ETA: 00:00:46\n",
      "Image 189/200 (5589) | Time/iter: 3.89s | ETA: 00:00:42\n",
      "Image 190/200 (5593) | Time/iter: 3.87s | ETA: 00:00:38\n",
      "Image 191/200 (5611) | Time/iter: 4.56s | ETA: 00:00:41\n",
      "Image 192/200 (5617) | Time/iter: 7.27s | ETA: 00:00:58\n",
      "Image 193/200 (5652) | Time/iter: 14.97s | ETA: 00:01:44\n",
      "Image 194/200 (5668) | Time/iter: 4.55s | ETA: 00:00:27\n",
      "Image 195/200 (5673) | Time/iter: 4.23s | ETA: 00:00:21\n",
      "Image 196/200 (5693) | Time/iter: 4.71s | ETA: 00:00:18\n",
      "Image 197/200 (5695) | Time/iter: 12.44s | ETA: 00:00:37\n",
      "Image 198/200 (5698) | Time/iter: 7.98s | ETA: 00:00:15\n",
      "Image 199/200 (5708) | Time/iter: 8.09s | ETA: 00:00:08\n",
      "Image 200/200 (5721) | Time/iter: 10.55s | ETA: 00:00:00\n",
      "ðŸŽ‰ IIW reflectance outputs saved in: E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\chroma_enhance_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "# IIW Dataset paths\n",
    "iiw_input_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\chroma_enhance_input\"\n",
    "iiw_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\chroma_enhance_output\"\n",
    "os.makedirs(iiw_output_dir, exist_ok=True)\n",
    "\n",
    "# --- Prevent accidental concurrent double-run (which duplicates output lines) ---\n",
    "if globals().get('_IIW_PROCESSING_ACTIVE', False):\n",
    "    raise RuntimeError(\"IIW processing already running in this kernel. Wait for it to finish or restart kernel.\")\n",
    "_IIW_PROCESSING_ACTIVE = True\n",
    "\n",
    "# --- Ensure dependencies from previous cell are available after a restart ---\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "try:\n",
    "    load_image\n",
    "except NameError:\n",
    "    from chrislib.data_util import load_image  # Will raise if unavailable\n",
    "try:\n",
    "    view\n",
    "except NameError:\n",
    "    from chrislib.general import view, invert\n",
    "try:\n",
    "    run_pipeline\n",
    "except NameError:\n",
    "    from intrinsic.pipeline import run_pipeline\n",
    "if 'models' not in globals():\n",
    "    _IIW_PROCESSING_ACTIVE = False\n",
    "    raise RuntimeError(\"'models' dict missing. Execute the model loading cell above.\")\n",
    "if 'device' not in globals():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def numeric_sort_key(path):\n",
    "    \"\"\"Return (leading_number, lowercase_name) for consistent numeric ordering.\"\"\"\n",
    "    fname = os.path.splitext(os.path.basename(path))[0]\n",
    "    m = re.match(r'^(\\d+)', fname)\n",
    "    if m:\n",
    "        return (int(m.group(1)), fname.lower())\n",
    "    return (float('inf'), fname.lower())\n",
    "\n",
    "# Collect images once (case-insensitive filtering) using os.listdir to avoid duplicate glob matches\n",
    "image_files = []\n",
    "for f in os.listdir(iiw_input_dir):\n",
    "    fl = f.lower()\n",
    "    if fl.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_files.append(os.path.join(iiw_input_dir, f))\n",
    "\n",
    "# Sort and take only the first N images\n",
    "iiw_image_paths = sorted(image_files, key=numeric_sort_key)\n",
    "MAX_TO_PROCESS = 1000\n",
    "batch_paths = iiw_image_paths[:MAX_TO_PROCESS]\n",
    "\n",
    "print(f\"Found {len(iiw_image_paths)} images in {iiw_input_dir}\")\n",
    "print(f\"Processing first {len(batch_paths)} images in numeric order\")\n",
    "if batch_paths:\n",
    "    preview = [os.path.splitext(os.path.basename(p))[0] for p in batch_paths[:15]]\n",
    "    print(\"Numeric processing order preview (first 15):\", preview)\n",
    "\n",
    "total_images = len(batch_paths)\n",
    "start_time = time.time()\n",
    "for idx, img_path in enumerate(batch_paths, 1):\n",
    "    iter_start = time.time()\n",
    "    image = load_image(img_path)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "    alb = view(results[\"hr_alb\"])\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(iiw_output_dir, f\"{fname}_reflectance.png\")\n",
    "    imwrite(out_path, alb_save)\n",
    "    iter_time = time.time() - iter_start\n",
    "    remaining = (total_images - idx) * iter_time\n",
    "    eta = time.strftime('%H:%M:%S', time.gmtime(max(0, remaining)))\n",
    "    print(f\"Image {idx}/{total_images} ({fname}) | Time/iter: {iter_time:.2f}s | ETA: {eta}\")\n",
    "\n",
    "print(f\"ðŸŽ‰ IIW reflectance outputs saved in: {iiw_output_dir}\")\n",
    "_IIW_PROCESSING_ACTIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e64b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [03:32<00:00,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your Synthetic Dense dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2358d91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_11340\\2795243844.py:54: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_11340\\2795243844.py:55: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARAP Albedo: LMSE=0.0718, RMSE=0.2246, SSIM=0.6957\n",
      "ARAP Shading: LMSE=0.0487, RMSE=0.2036, SSIM=0.7175\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ARAP paths (use raw strings to avoid escape issues)\n",
    "arap_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_output\\albedo\"\n",
    "arap_pred_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\chroma_enhance_output\\shading\"\n",
    "arap_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Albedo\"\n",
    "arap_gt_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Shading\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    # Drop alpha if present, then convert to grayscale and squeeze to 2D\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    # Ensure odd window <= min(h, w); fallback to 3 if needed\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3:\n",
    "        win = 3\n",
    "    if win % 2 == 0:\n",
    "        win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def compute_metrics(pred_dir, gt_dir, metric_type):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if metric_type == 'alb' and (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            base_name = fname.rsplit('_alb', 1)[0]\n",
    "            gt_suffix = '_albedo'\n",
    "        elif metric_type == 'shd' and (low.endswith('_shd.png') or low.endswith('_shd.jpg') or low.endswith('_shd.jpeg')):\n",
    "            base_name = fname.rsplit('_shd', 1)[0]\n",
    "            gt_suffix = '_shading'\n",
    "        else:\n",
    "            print(f\"Skipping {fname} (unexpected suffix)\")\n",
    "            continue\n",
    "        gt_file = None\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            candidate = f\"{base_name}{gt_suffix}{ext}\"\n",
    "            if os.path.exists(os.path.join(gt_dir, candidate)):\n",
    "                gt_file = candidate\n",
    "                break\n",
    "        if gt_file is None:\n",
    "            print(f\"No GT found for {fname}\")\n",
    "            continue\n",
    "        pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
    "        gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n",
    "        # Grayscale first, strictly 2D\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        # Resize only grayscale to match shapes\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        # LMSE implementation on grayscale\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                # If image too small for one window, fallback to global MSE\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gt_patch = gt[i:i+window_size, j:j+window_size]\n",
    "                    pred_patch = pred[i:i+window_size, j:j+window_size]\n",
    "                    mse = np.mean((gt_patch - pred_patch) ** 2)\n",
    "                    errors.append(mse)\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_val = lmse(gt_gray, pred_gray, window_size=20, window_shift=10)\n",
    "        rmse_val = float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2)))\n",
    "        ssim_val = float(safe_ssim(pred_gray, gt_gray))\n",
    "        lmse_vals.append(lmse_val)\n",
    "        rmse_vals.append(rmse_val)\n",
    "        ssim_vals.append(ssim_val)\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "# Compute metrics for albedo\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_metrics(arap_pred_albedo_dir, arap_gt_albedo_dir, metric_type='alb')\n",
    "print(f\"ARAP Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")\n",
    "\n",
    "# Compute metrics for shading\n",
    "lmse_shd, rmse_shd, ssim_shd = compute_metrics(arap_pred_shading_dir, arap_gt_shading_dir, metric_type='shd')\n",
    "print(f\"ARAP Shading: LMSE={lmse_shd:.4f}, RMSE={rmse_shd:.4f}, SSIM={ssim_shd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "812b23e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014: WHDR=0.5958\n",
      "1068: WHDR=0.0826\n",
      "1094: WHDR=0.1339\n",
      "1118: WHDR=0.2699\n",
      "1127: WHDR=0.0177\n",
      "1141: WHDR=0.2506\n",
      "1143: WHDR=0.3104\n",
      "116: WHDR=0.0344\n",
      "1195: WHDR=0.1232\n",
      "119: WHDR=0.2411\n",
      "1206: WHDR=0.2013\n",
      "1221: WHDR=0.4069\n",
      "1226: WHDR=0.2144\n",
      "1232: WHDR=0.3250\n",
      "1245: WHDR=0.1203\n",
      "1302: WHDR=0.2905\n",
      "1376: WHDR=0.2098\n",
      "141: WHDR=0.1898\n",
      "1453: WHDR=0.1990\n",
      "1694: WHDR=0.0964\n",
      "176: WHDR=0.1587\n",
      "180: WHDR=0.2684\n",
      "182: WHDR=0.1362\n",
      "1934: WHDR=0.1561\n",
      "2066: WHDR=0.1163\n",
      "2200: WHDR=0.0829\n",
      "2232: WHDR=0.2057\n",
      "2237: WHDR=0.2553\n",
      "2254: WHDR=0.1300\n",
      "227: WHDR=0.0955\n",
      "2301: WHDR=0.0929\n",
      "2305: WHDR=0.5343\n",
      "2311: WHDR=0.0474\n",
      "2324: WHDR=0.4163\n",
      "2349: WHDR=0.2821\n",
      "2352: WHDR=0.1652\n",
      "2355: WHDR=0.1009\n",
      "2377: WHDR=0.1646\n",
      "239: WHDR=0.0123\n",
      "2406: WHDR=0.2100\n",
      "245: WHDR=0.1256\n",
      "2466: WHDR=0.3040\n",
      "2471: WHDR=0.3232\n",
      "2476: WHDR=0.2236\n",
      "2504: WHDR=0.2365\n",
      "253: WHDR=0.3512\n",
      "2545: WHDR=0.0761\n",
      "2547: WHDR=0.2329\n",
      "2548: WHDR=0.2314\n",
      "257: WHDR=0.1421\n",
      "2598: WHDR=0.1912\n",
      "2602: WHDR=0.2574\n",
      "2606: WHDR=0.2218\n",
      "2615: WHDR=0.2304\n",
      "2620: WHDR=0.1578\n",
      "262: WHDR=0.8022\n",
      "2636: WHDR=0.4324\n",
      "2715: WHDR=0.3095\n",
      "2727: WHDR=0.2592\n",
      "2758: WHDR=0.1942\n",
      "277: WHDR=0.2188\n",
      "2789: WHDR=0.2178\n",
      "2828: WHDR=0.2581\n",
      "2894: WHDR=0.3263\n",
      "2910: WHDR=0.2776\n",
      "2970: WHDR=0.2803\n",
      "2998: WHDR=0.5842\n",
      "3044: WHDR=0.2181\n",
      "3072: WHDR=0.2428\n",
      "3136: WHDR=0.3055\n",
      "3199: WHDR=0.2850\n",
      "3219: WHDR=0.1376\n",
      "3221: WHDR=0.1159\n",
      "3240: WHDR=0.1948\n",
      "3246: WHDR=0.2050\n",
      "3247: WHDR=0.2280\n",
      "3254: WHDR=0.2541\n",
      "3305: WHDR=0.1576\n",
      "3308: WHDR=0.0910\n",
      "3353: WHDR=0.0804\n",
      "3363: WHDR=0.2559\n",
      "3392: WHDR=0.2219\n",
      "3400: WHDR=0.2240\n",
      "3403: WHDR=0.2732\n",
      "3438: WHDR=0.0795\n",
      "3446: WHDR=0.1838\n",
      "3463: WHDR=0.2562\n",
      "3466: WHDR=0.1394\n",
      "3544: WHDR=0.2818\n",
      "3592: WHDR=0.2667\n",
      "3625: WHDR=0.3235\n",
      "3642: WHDR=0.1089\n",
      "3679: WHDR=0.1749\n",
      "3701: WHDR=0.2673\n",
      "370: WHDR=0.4324\n",
      "3715: WHDR=0.2861\n",
      "3730: WHDR=0.1153\n",
      "3773: WHDR=0.3333\n",
      "3859: WHDR=0.2691\n",
      "3864: WHDR=0.1574\n",
      "3877: WHDR=0.2229\n",
      "3916: WHDR=0.2047\n",
      "3932: WHDR=0.2809\n",
      "3958: WHDR=0.2545\n",
      "4023: WHDR=0.3578\n",
      "4032: WHDR=0.0915\n",
      "4037: WHDR=0.2311\n",
      "4057: WHDR=0.1852\n",
      "4131: WHDR=0.3718\n",
      "4136: WHDR=0.2008\n",
      "417: WHDR=0.1455\n",
      "4203: WHDR=0.3097\n",
      "4217: WHDR=0.3282\n",
      "4259: WHDR=0.4774\n",
      "4264: WHDR=0.2251\n",
      "4269: WHDR=0.2538\n",
      "4287: WHDR=0.3389\n",
      "4302: WHDR=0.3036\n",
      "434: WHDR=0.2869\n",
      "4392: WHDR=0.2789\n",
      "4440: WHDR=0.3089\n",
      "4495: WHDR=0.3570\n",
      "4496: WHDR=0.3467\n",
      "4542: WHDR=0.2080\n",
      "4574: WHDR=0.4058\n",
      "4593: WHDR=0.3912\n",
      "4627: WHDR=0.0952\n",
      "4687: WHDR=0.2957\n",
      "4746: WHDR=0.2991\n",
      "4767: WHDR=0.1717\n",
      "4788: WHDR=0.3934\n",
      "4796: WHDR=0.2696\n",
      "4823: WHDR=0.2093\n",
      "4825: WHDR=0.1831\n",
      "4856: WHDR=0.3526\n",
      "491: WHDR=0.1247\n",
      "4934: WHDR=0.0695\n",
      "498: WHDR=0.2148\n",
      "4991: WHDR=0.1473\n",
      "502: WHDR=0.1110\n",
      "5049: WHDR=0.1635\n",
      "504: WHDR=0.1405\n",
      "5059: WHDR=0.2859\n",
      "5062: WHDR=0.2125\n",
      "5214: WHDR=0.1093\n",
      "5234: WHDR=0.2582\n",
      "5249: WHDR=0.3341\n",
      "5253: WHDR=0.2150\n",
      "5254: WHDR=0.2533\n",
      "527: WHDR=0.1516\n",
      "5285: WHDR=0.4155\n",
      "5360: WHDR=0.1119\n",
      "5382: WHDR=0.1329\n",
      "5383: WHDR=0.1451\n",
      "5460: WHDR=0.1112\n",
      "54: WHDR=0.1632\n",
      "5568: WHDR=0.2318\n",
      "5589: WHDR=0.1794\n",
      "5593: WHDR=0.3556\n",
      "560: WHDR=0.4577\n",
      "5611: WHDR=0.4015\n",
      "5617: WHDR=0.3156\n",
      "5652: WHDR=0.2073\n",
      "5668: WHDR=0.3156\n",
      "5673: WHDR=0.2306\n",
      "5693: WHDR=0.2393\n",
      "5695: WHDR=0.3889\n",
      "5698: WHDR=0.2768\n",
      "5708: WHDR=0.1648\n",
      "5721: WHDR=0.3246\n",
      "579: WHDR=0.1825\n",
      "593: WHDR=0.2366\n",
      "594: WHDR=0.1984\n",
      "597: WHDR=0.1435\n",
      "611: WHDR=0.3004\n",
      "613: WHDR=0.1143\n",
      "627: WHDR=0.1231\n",
      "633: WHDR=0.1888\n",
      "63: WHDR=0.1345\n",
      "653: WHDR=0.1617\n",
      "657: WHDR=0.1513\n",
      "662: WHDR=0.1709\n",
      "686: WHDR=0.0729\n",
      "749: WHDR=0.1978\n",
      "760: WHDR=0.0956\n",
      "771: WHDR=0.1476\n",
      "791: WHDR=0.1959\n",
      "815: WHDR=0.1377\n",
      "821: WHDR=0.1593\n",
      "827: WHDR=0.0928\n",
      "844: WHDR=0.1482\n",
      "845: WHDR=0.1240\n",
      "856: WHDR=0.1063\n",
      "859: WHDR=0.0926\n",
      "860: WHDR=0.0996\n",
      "876: WHDR=0.2376\n",
      "918: WHDR=0.2043\n",
      "922: WHDR=0.0848\n",
      "952: WHDR=0.2173\n",
      "953: WHDR=0.2268\n",
      "\n",
      "Evaluated 200 images. Mean WHDR = 0.2246\n"
     ]
    }
   ],
   "source": [
    "# Compute WHDR for IIW outputs using attached whdr logic (Python 3 safe)\n",
    "import os, json, sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Paths (raw strings for Windows)\n",
    "iiW_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\chroma_enhance_output\"\n",
    "iiW_annotations_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\annotations\"\n",
    "\n",
    "# --- WHDR utilities (ported to Py3, in-notebook) ---\n",
    "def srgb_to_rgb(srgb):\n",
    "    srgb = np.asarray(srgb, dtype=np.float32)\n",
    "    ret = np.zeros_like(srgb, dtype=np.float32)\n",
    "    idx0 = srgb <= 0.04045\n",
    "    idx1 = ~idx0\n",
    "    ret[idx0] = srgb[idx0] / 12.92\n",
    "    ret[idx1] = np.power((srgb[idx1] + 0.055) / 1.055, 2.4)\n",
    "    return ret\n",
    "\n",
    "def load_image_linear(filename, is_srgb=True):\n",
    "    if not filename:\n",
    "        raise ValueError(\"Empty filename\")\n",
    "    image = np.asarray(Image.open(filename)).astype(np.float32) / 255.0\n",
    "    if is_srgb:\n",
    "        return srgb_to_rgb(image)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def compute_whdr(reflectance, judgements, delta=0.10):\n",
    "    points = judgements['intrinsic_points']\n",
    "    comparisons = judgements['intrinsic_comparisons']\n",
    "    id_to_points = {p['id']: p for p in points}\n",
    "    rows, cols = reflectance.shape[0:2]\n",
    "\n",
    "    error_sum = 0.0\n",
    "    weight_sum = 0.0\n",
    "\n",
    "    for c in comparisons:\n",
    "        darker = c.get('darker')\n",
    "        if darker not in ('1', '2', 'E'):\n",
    "            continue\n",
    "\n",
    "        weight = c.get('darker_score')\n",
    "        if weight is None or weight <= 0:\n",
    "            continue\n",
    "\n",
    "        p1 = id_to_points.get(c['point1'])\n",
    "        p2 = id_to_points.get(c['point2'])\n",
    "        if p1 is None or p2 is None:\n",
    "            continue\n",
    "        if not p1.get('opaque', False) or not p2.get('opaque', False):\n",
    "            continue\n",
    "\n",
    "        y1 = min(rows - 1, max(0, int(p1['y'] * rows)))\n",
    "        x1 = min(cols - 1, max(0, int(p1['x'] * cols)))\n",
    "        y2 = min(rows - 1, max(0, int(p2['y'] * rows)))\n",
    "        x2 = min(cols - 1, max(0, int(p2['x'] * cols)))\n",
    "\n",
    "        l1 = max(1e-10, float(np.mean(reflectance[y1, x1, ...])))\n",
    "        l2 = max(1e-10, float(np.mean(reflectance[y2, x2, ...])))\n",
    "\n",
    "        if l2 / l1 > 1.0 + delta:\n",
    "            alg_darker = '1'\n",
    "        elif l1 / l2 > 1.0 + delta:\n",
    "            alg_darker = '2'\n",
    "        else:\n",
    "            alg_darker = 'E'\n",
    "\n",
    "        if darker != alg_darker:\n",
    "            error_sum += weight\n",
    "        weight_sum += weight\n",
    "\n",
    "    if weight_sum > 0:\n",
    "        return error_sum / weight_sum\n",
    "    return None\n",
    "\n",
    "# --- Batch evaluation over available outputs ---\n",
    "# We only evaluate files present in the output directory; we expect names like 1014_reflectance.png\n",
    "valid_exts = ('.png', '.jpg', '.jpeg')\n",
    "reflectance_files = [f for f in os.listdir(iiW_output_dir) if f.lower().endswith(valid_exts) and '_reflectance' in f]\n",
    "reflectance_files.sort()\n",
    "\n",
    "results = []\n",
    "for f in reflectance_files:\n",
    "    stem = os.path.splitext(f)[0]\n",
    "    # Expect pattern <photoid>_reflectance\n",
    "    if not stem.endswith('_reflectance'):\n",
    "        continue\n",
    "    photo_id = stem.rsplit('_reflectance', 1)[0]\n",
    "    json_path = os.path.join(iiW_annotations_dir, f\"{photo_id}.json\")\n",
    "    img_path = os.path.join(iiW_output_dir, f)\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Skipping {f}: missing annotations {photo_id}.json\")\n",
    "        continue\n",
    "    try:\n",
    "        refl = load_image_linear(img_path, is_srgb=True)  # saved PNGs are sRGB; convert to linear\n",
    "        with open(json_path, 'r') as jf:\n",
    "            judg = json.load(jf)\n",
    "        score = compute_whdr(refl, judg, delta=0.10)\n",
    "        if score is None:\n",
    "            print(f\"{photo_id}: no valid judgements; WHDR=None\")\n",
    "            continue\n",
    "        results.append((photo_id, score))\n",
    "        print(f\"{photo_id}: WHDR={score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{photo_id}: error computing WHDR -> {e}\")\n",
    "\n",
    "if results:\n",
    "    mean_whdr = float(np.mean([s for _, s in results]))\n",
    "    print(f\"\\nEvaluated {len(results)} images. Mean WHDR = {mean_whdr:.4f}\")\n",
    "else:\n",
    "    print(\"No WHDR scores computed. Ensure output images and matching JSONs exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533f3bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_11340\\3020109363.py:61: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_11340\\3020109363.py:62: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(gt_path).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 22 pairs; Missing GT for 1 files.\n",
      "Synthetic Dense Albedo: LMSE=0.0951, RMSE=0.3015, SSIM=0.5561\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Dense Albedo Metrics Only (LMSE, RMSE, SSIM) with robust GT matching\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Synthetic Dense paths (update if your dataset root differs)\n",
    "sd_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\chroma_enhance_output\\albedo\"\n",
    "sd_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\Gt_albedo\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3: win = 3\n",
    "    if win % 2 == 0: win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def find_gt_file(gt_dir: str, stem: str):\n",
    "    candidates = []\n",
    "    # Common direct patterns\n",
    "    for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "        candidates.append(f\"{stem}_albedo{ext}\")\n",
    "        candidates.append(f\"{stem}{ext}\")\n",
    "    for c in candidates:\n",
    "        p = os.path.join(gt_dir, c)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    # Fallback: scan directory for files that start with stem and contain 'alb' or 'albedo'\n",
    "    low_stem = stem.lower()\n",
    "    for f in os.listdir(gt_dir):\n",
    "        fl = f.lower()\n",
    "        if (fl.startswith(low_stem)) and (('albedo' in fl) or ('alb' in fl)) and fl.endswith(tuple(['.png','.jpg','.jpeg','.PNG','.JPG','.JPEG'])):\n",
    "            return os.path.join(gt_dir, f)\n",
    "    return None\n",
    "\n",
    "def compute_albedo_metrics(pred_dir, gt_dir):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if not pred_files:\n",
    "        print(f\"âš  No predicted albedo files found in {pred_dir}\")\n",
    "        return None, None, None\n",
    "    matched = 0; missing = 0\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if not (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            continue\n",
    "        stem = fname.rsplit('_alb', 1)[0]\n",
    "        gt_path = find_gt_file(gt_dir, stem)\n",
    "        if gt_path is None:\n",
    "            missing += 1\n",
    "            continue\n",
    "        pred_path = os.path.join(pred_dir, fname)\n",
    "        pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
    "        gt_img = imread(gt_path).astype(np.float32) / 255.0\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gpatch = gt[i:i+window_size, j:j+window_size]\n",
    "                    ppatch = pred[i:i+window_size, j:j+window_size]\n",
    "                    errors.append(np.mean((gpatch - ppatch) ** 2))\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_vals.append(lmse(gt_gray, pred_gray))\n",
    "        rmse_vals.append(float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2))))\n",
    "        ssim_vals.append(float(safe_ssim(pred_gray, gt_gray)))\n",
    "        matched += 1\n",
    "    if matched == 0:\n",
    "        print(f\"âš  No GT matches found in {gt_dir} for stems of predictions in {pred_dir}. Check naming.\")\n",
    "        if missing > 0:\n",
    "            print(f\"   Missing GT for {missing} predicted files.\")\n",
    "        return None, None, None\n",
    "    print(f\"Matched {matched} pairs; Missing GT for {missing} files.\")\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_albedo_metrics(sd_pred_albedo_dir, sd_gt_albedo_dir)\n",
    "if lmse_alb is None:\n",
    "    print(\"Synthetic Dense Albedo: metrics unavailable (no matched pairs).\")\n",
    "else:\n",
    "    print(f\"Synthetic Dense Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
