{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc68bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\COLLEGE MATERIAL\\Ordinal_Shading\n"
     ]
    }
   ],
   "source": [
    "# 1. LCDPNet Inputs: Import and Environment Setup\n",
    "%cd E:\\COLLEGE MATERIAL\\Ordinal_Shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d56a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d5b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Ensure local imports work\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "\n",
    "from chrislib.general import view, invert\n",
    "from chrislib.data_util import load_image\n",
    "from intrinsic.pipeline import run_pipeline\n",
    "from altered_midas.midas_net import MidasNet\n",
    "from altered_midas.midas_net_custom import MidasNet_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55d5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading models manually from local weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models loaded\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------\n",
    "# MANUAL MODEL LOADING (local weights)\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¦ Loading models manually from local weights...\")\n",
    "model_dir = \"models\"\n",
    "ord_model = MidasNet()\n",
    "ord_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_0_v21.pt\"), map_location=device))\n",
    "ord_model.eval()\n",
    "ord_model = ord_model.to(device)\n",
    "\n",
    "iid_model = MidasNet_small(exportable=False, input_channels=5, output_channels=1)\n",
    "iid_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_1_v21.pt\"), map_location=device))\n",
    "iid_model.eval()\n",
    "iid_model = iid_model.to(device)\n",
    "\n",
    "col_model = MidasNet(activation='sigmoid', input_channels=7, output_channels=2)\n",
    "col_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_2_v21.pt\"), map_location=device))\n",
    "col_model.eval()\n",
    "col_model = col_model.to(device)\n",
    "\n",
    "alb_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3, last_residual=True)\n",
    "alb_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_3_v21.pt\"), map_location=device))\n",
    "alb_model.eval()\n",
    "alb_model = alb_model.to(device)\n",
    "\n",
    "dif_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3)\n",
    "dif_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_4_v21.pt\"), map_location=device))\n",
    "dif_model.eval()\n",
    "dif_model = dif_model.to(device)\n",
    "\n",
    "models = {\n",
    "    \"ord_model\": ord_model,\n",
    "    \"iid_model\": iid_model,\n",
    "    \"col_model\": col_model,\n",
    "    \"alb_model\": alb_model,\n",
    "    \"dif_model\": dif_model,\n",
    "}\n",
    "print(\"âœ… Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0510fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [04:56<00:00, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your ARAP dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e81fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\smoothing_input\n",
      "Processing first 200 images in numeric order\n",
      "Numeric processing order preview (first 15): ['54', '63', '116', '119', '141', '176', '180', '182', '227', '239', '245', '253', '257', '262', '277']\n",
      "Image 1/200 (54) | Time/iter: 4.43s | ETA: 00:14:41\n",
      "Image 2/200 (63) | Time/iter: 4.87s | ETA: 00:16:03\n",
      "Image 3/200 (116) | Time/iter: 4.52s | ETA: 00:14:50\n",
      "Image 4/200 (119) | Time/iter: 4.04s | ETA: 00:13:12\n",
      "Image 5/200 (141) | Time/iter: 4.64s | ETA: 00:15:05\n",
      "Image 6/200 (176) | Time/iter: 4.07s | ETA: 00:13:08\n",
      "Image 7/200 (180) | Time/iter: 4.22s | ETA: 00:13:34\n",
      "Image 8/200 (182) | Time/iter: 4.56s | ETA: 00:14:35\n",
      "Image 9/200 (227) | Time/iter: 4.02s | ETA: 00:12:47\n",
      "Image 10/200 (239) | Time/iter: 4.32s | ETA: 00:13:41\n",
      "Image 11/200 (245) | Time/iter: 4.78s | ETA: 00:15:02\n",
      "Image 12/200 (253) | Time/iter: 4.29s | ETA: 00:13:26\n",
      "Image 13/200 (257) | Time/iter: 4.14s | ETA: 00:12:53\n",
      "Image 14/200 (262) | Time/iter: 4.07s | ETA: 00:12:36\n",
      "Image 15/200 (277) | Time/iter: 4.55s | ETA: 00:14:01\n",
      "Image 16/200 (370) | Time/iter: 4.07s | ETA: 00:12:29\n",
      "Image 17/200 (417) | Time/iter: 7.79s | ETA: 00:23:45\n",
      "Image 18/200 (434) | Time/iter: 7.63s | ETA: 00:23:08\n",
      "Image 19/200 (491) | Time/iter: 7.67s | ETA: 00:23:08\n",
      "Image 20/200 (498) | Time/iter: 4.61s | ETA: 00:13:49\n",
      "Image 21/200 (502) | Time/iter: 4.25s | ETA: 00:12:40\n",
      "Image 22/200 (504) | Time/iter: 7.54s | ETA: 00:22:21\n",
      "Image 23/200 (527) | Time/iter: 7.67s | ETA: 00:22:36\n",
      "Image 24/200 (560) | Time/iter: 4.28s | ETA: 00:12:33\n",
      "Image 25/200 (579) | Time/iter: 4.61s | ETA: 00:13:26\n",
      "Image 26/200 (593) | Time/iter: 9.31s | ETA: 00:26:59\n",
      "Image 27/200 (594) | Time/iter: 4.17s | ETA: 00:12:01\n",
      "Image 28/200 (597) | Time/iter: 4.66s | ETA: 00:13:20\n",
      "Image 29/200 (611) | Time/iter: 4.36s | ETA: 00:12:25\n",
      "Image 30/200 (613) | Time/iter: 7.66s | ETA: 00:21:41\n",
      "Image 31/200 (627) | Time/iter: 6.91s | ETA: 00:19:27\n",
      "Image 32/200 (633) | Time/iter: 3.83s | ETA: 00:10:43\n",
      "Image 33/200 (653) | Time/iter: 3.76s | ETA: 00:10:28\n",
      "Image 34/200 (657) | Time/iter: 4.30s | ETA: 00:11:53\n",
      "Image 35/200 (662) | Time/iter: 3.80s | ETA: 00:10:27\n",
      "Image 36/200 (686) | Time/iter: 4.32s | ETA: 00:11:47\n",
      "Image 37/200 (749) | Time/iter: 3.80s | ETA: 00:10:19\n",
      "Image 38/200 (760) | Time/iter: 6.83s | ETA: 00:18:25\n",
      "Image 39/200 (771) | Time/iter: 3.93s | ETA: 00:10:32\n",
      "Image 40/200 (791) | Time/iter: 6.94s | ETA: 00:18:31\n",
      "Image 41/200 (815) | Time/iter: 3.95s | ETA: 00:10:27\n",
      "Image 42/200 (821) | Time/iter: 3.79s | ETA: 00:09:59\n",
      "Image 43/200 (827) | Time/iter: 6.86s | ETA: 00:17:56\n",
      "Image 44/200 (844) | Time/iter: 4.28s | ETA: 00:11:07\n",
      "Image 45/200 (845) | Time/iter: 4.24s | ETA: 00:10:57\n",
      "Image 46/200 (856) | Time/iter: 3.81s | ETA: 00:09:46\n",
      "Image 47/200 (859) | Time/iter: 3.91s | ETA: 00:09:58\n",
      "Image 48/200 (860) | Time/iter: 4.27s | ETA: 00:10:48\n",
      "Image 49/200 (876) | Time/iter: 4.32s | ETA: 00:10:52\n",
      "Image 50/200 (918) | Time/iter: 3.77s | ETA: 00:09:26\n",
      "Image 51/200 (922) | Time/iter: 4.24s | ETA: 00:10:31\n",
      "Image 52/200 (952) | Time/iter: 10.18s | ETA: 00:25:06\n",
      "Image 53/200 (953) | Time/iter: 7.05s | ETA: 00:17:15\n",
      "Image 54/200 (1014) | Time/iter: 5.11s | ETA: 00:12:25\n",
      "Image 55/200 (1068) | Time/iter: 3.80s | ETA: 00:09:11\n",
      "Image 56/200 (1094) | Time/iter: 4.29s | ETA: 00:10:17\n",
      "Image 57/200 (1118) | Time/iter: 4.26s | ETA: 00:10:08\n",
      "Image 58/200 (1127) | Time/iter: 10.34s | ETA: 00:24:28\n",
      "Image 59/200 (1141) | Time/iter: 4.48s | ETA: 00:10:31\n",
      "Image 60/200 (1143) | Time/iter: 4.96s | ETA: 00:11:34\n",
      "Image 61/200 (1195) | Time/iter: 3.86s | ETA: 00:08:56\n",
      "Image 62/200 (1206) | Time/iter: 3.83s | ETA: 00:08:47\n",
      "Image 63/200 (1221) | Time/iter: 4.03s | ETA: 00:09:12\n",
      "Image 64/200 (1226) | Time/iter: 3.96s | ETA: 00:08:58\n",
      "Image 65/200 (1232) | Time/iter: 6.91s | ETA: 00:15:32\n",
      "Image 66/200 (1245) | Time/iter: 4.05s | ETA: 00:09:02\n",
      "Image 67/200 (1302) | Time/iter: 6.84s | ETA: 00:15:09\n",
      "Image 68/200 (1376) | Time/iter: 4.25s | ETA: 00:09:20\n",
      "Image 69/200 (1453) | Time/iter: 6.85s | ETA: 00:14:56\n",
      "Image 70/200 (1694) | Time/iter: 4.20s | ETA: 00:09:06\n",
      "Image 71/200 (1934) | Time/iter: 4.25s | ETA: 00:09:07\n",
      "Image 72/200 (2066) | Time/iter: 6.96s | ETA: 00:14:50\n",
      "Image 73/200 (2200) | Time/iter: 4.86s | ETA: 00:10:17\n",
      "Image 74/200 (2232) | Time/iter: 3.48s | ETA: 00:07:18\n",
      "Image 75/200 (2237) | Time/iter: 3.81s | ETA: 00:07:56\n",
      "Image 76/200 (2254) | Time/iter: 3.78s | ETA: 00:07:48\n",
      "Image 77/200 (2301) | Time/iter: 4.27s | ETA: 00:08:44\n",
      "Image 78/200 (2305) | Time/iter: 10.08s | ETA: 00:20:29\n",
      "Image 79/200 (2311) | Time/iter: 4.59s | ETA: 00:09:15\n",
      "Image 80/200 (2324) | Time/iter: 7.56s | ETA: 00:15:06\n",
      "Image 81/200 (2349) | Time/iter: 4.29s | ETA: 00:08:30\n",
      "Image 82/200 (2352) | Time/iter: 6.98s | ETA: 00:13:43\n",
      "Image 83/200 (2355) | Time/iter: 4.27s | ETA: 00:08:19\n",
      "Image 84/200 (2377) | Time/iter: 7.23s | ETA: 00:13:58\n",
      "Image 85/200 (2406) | Time/iter: 4.35s | ETA: 00:08:20\n",
      "Image 86/200 (2466) | Time/iter: 4.52s | ETA: 00:08:34\n",
      "Image 87/200 (2471) | Time/iter: 4.44s | ETA: 00:08:21\n",
      "Image 88/200 (2476) | Time/iter: 4.13s | ETA: 00:07:42\n",
      "Image 89/200 (2504) | Time/iter: 7.86s | ETA: 00:14:31\n",
      "Image 90/200 (2545) | Time/iter: 3.97s | ETA: 00:07:16\n",
      "Image 91/200 (2547) | Time/iter: 4.38s | ETA: 00:07:57\n",
      "Image 92/200 (2548) | Time/iter: 7.41s | ETA: 00:13:20\n",
      "Image 93/200 (2598) | Time/iter: 4.38s | ETA: 00:07:49\n",
      "Image 94/200 (2602) | Time/iter: 7.25s | ETA: 00:12:48\n",
      "Image 95/200 (2606) | Time/iter: 4.35s | ETA: 00:07:37\n",
      "Image 96/200 (2615) | Time/iter: 10.57s | ETA: 00:18:19\n",
      "Image 97/200 (2620) | Time/iter: 4.56s | ETA: 00:07:49\n",
      "Image 98/200 (2636) | Time/iter: 4.38s | ETA: 00:07:26\n",
      "Image 99/200 (2715) | Time/iter: 19.15s | ETA: 00:32:14\n",
      "Image 100/200 (2727) | Time/iter: 4.37s | ETA: 00:07:16\n",
      "Image 101/200 (2758) | Time/iter: 3.91s | ETA: 00:06:27\n",
      "Image 102/200 (2789) | Time/iter: 3.96s | ETA: 00:06:27\n",
      "Image 103/200 (2828) | Time/iter: 18.99s | ETA: 00:30:42\n",
      "Image 104/200 (2894) | Time/iter: 4.54s | ETA: 00:07:16\n",
      "Image 105/200 (2910) | Time/iter: 4.49s | ETA: 00:07:06\n",
      "Image 106/200 (2970) | Time/iter: 7.23s | ETA: 00:11:19\n",
      "Image 107/200 (2998) | Time/iter: 7.13s | ETA: 00:11:03\n",
      "Image 108/200 (3044) | Time/iter: 3.90s | ETA: 00:05:59\n",
      "Image 109/200 (3072) | Time/iter: 4.39s | ETA: 00:06:39\n",
      "Image 110/200 (3136) | Time/iter: 4.38s | ETA: 00:06:33\n",
      "Image 111/200 (3199) | Time/iter: 4.44s | ETA: 00:06:34\n",
      "Image 112/200 (3219) | Time/iter: 3.94s | ETA: 00:05:46\n",
      "Image 113/200 (3221) | Time/iter: 4.39s | ETA: 00:06:21\n",
      "Image 114/200 (3240) | Time/iter: 4.18s | ETA: 00:05:59\n",
      "Image 115/200 (3246) | Time/iter: 4.09s | ETA: 00:05:47\n",
      "Image 116/200 (3247) | Time/iter: 4.37s | ETA: 00:06:06\n",
      "Image 117/200 (3254) | Time/iter: 7.33s | ETA: 00:10:08\n",
      "Image 118/200 (3305) | Time/iter: 3.93s | ETA: 00:05:22\n",
      "Image 119/200 (3308) | Time/iter: 5.22s | ETA: 00:07:02\n",
      "Image 120/200 (3353) | Time/iter: 5.23s | ETA: 00:06:58\n",
      "Image 121/200 (3363) | Time/iter: 12.31s | ETA: 00:16:12\n",
      "Image 122/200 (3392) | Time/iter: 4.52s | ETA: 00:05:52\n",
      "Image 123/200 (3400) | Time/iter: 3.71s | ETA: 00:04:45\n",
      "Image 124/200 (3403) | Time/iter: 7.22s | ETA: 00:09:08\n",
      "Image 125/200 (3438) | Time/iter: 7.56s | ETA: 00:09:26\n",
      "Image 126/200 (3446) | Time/iter: 4.00s | ETA: 00:04:56\n",
      "Image 127/200 (3463) | Time/iter: 4.72s | ETA: 00:05:44\n",
      "Image 128/200 (3466) | Time/iter: 7.53s | ETA: 00:09:01\n",
      "Image 129/200 (3544) | Time/iter: 11.08s | ETA: 00:13:06\n",
      "Image 130/200 (3592) | Time/iter: 7.15s | ETA: 00:08:20\n",
      "Image 131/200 (3625) | Time/iter: 12.17s | ETA: 00:13:59\n",
      "Image 132/200 (3642) | Time/iter: 4.21s | ETA: 00:04:46\n",
      "Image 133/200 (3679) | Time/iter: 4.79s | ETA: 00:05:21\n",
      "Image 134/200 (3701) | Time/iter: 4.38s | ETA: 00:04:49\n",
      "Image 135/200 (3715) | Time/iter: 19.22s | ETA: 00:20:49\n",
      "Image 136/200 (3730) | Time/iter: 7.13s | ETA: 00:07:36\n",
      "Image 137/200 (3773) | Time/iter: 4.34s | ETA: 00:04:33\n",
      "Image 138/200 (3859) | Time/iter: 7.23s | ETA: 00:07:28\n",
      "Image 139/200 (3864) | Time/iter: 7.18s | ETA: 00:07:18\n",
      "Image 140/200 (3877) | Time/iter: 4.40s | ETA: 00:04:24\n",
      "Image 141/200 (3916) | Time/iter: 3.89s | ETA: 00:03:49\n",
      "Image 142/200 (3932) | Time/iter: 10.55s | ETA: 00:10:11\n",
      "Image 143/200 (3958) | Time/iter: 7.53s | ETA: 00:07:09\n",
      "Image 144/200 (4023) | Time/iter: 7.17s | ETA: 00:06:41\n",
      "Image 145/200 (4032) | Time/iter: 7.09s | ETA: 00:06:29\n",
      "Image 146/200 (4037) | Time/iter: 4.36s | ETA: 00:03:55\n",
      "Image 147/200 (4057) | Time/iter: 4.38s | ETA: 00:03:52\n",
      "Image 148/200 (4131) | Time/iter: 3.84s | ETA: 00:03:19\n",
      "Image 149/200 (4136) | Time/iter: 10.44s | ETA: 00:08:52\n",
      "Image 150/200 (4203) | Time/iter: 7.76s | ETA: 00:06:27\n",
      "Image 151/200 (4217) | Time/iter: 14.90s | ETA: 00:12:10\n",
      "Image 152/200 (4259) | Time/iter: 22.58s | ETA: 00:18:03\n",
      "Image 153/200 (4264) | Time/iter: 10.78s | ETA: 00:08:26\n",
      "Image 154/200 (4269) | Time/iter: 7.26s | ETA: 00:05:33\n",
      "Image 155/200 (4287) | Time/iter: 7.14s | ETA: 00:05:21\n",
      "Image 156/200 (4302) | Time/iter: 7.15s | ETA: 00:05:14\n",
      "Image 157/200 (4392) | Time/iter: 4.01s | ETA: 00:02:52\n",
      "Image 158/200 (4440) | Time/iter: 4.00s | ETA: 00:02:47\n",
      "Image 159/200 (4495) | Time/iter: 10.06s | ETA: 00:06:52\n",
      "Image 160/200 (4496) | Time/iter: 3.91s | ETA: 00:02:36\n",
      "Image 161/200 (4542) | Time/iter: 10.57s | ETA: 00:06:52\n",
      "Image 162/200 (4574) | Time/iter: 10.67s | ETA: 00:06:45\n",
      "Image 163/200 (4593) | Time/iter: 10.61s | ETA: 00:06:32\n",
      "Image 164/200 (4627) | Time/iter: 10.56s | ETA: 00:06:20\n",
      "Image 165/200 (4687) | Time/iter: 5.35s | ETA: 00:03:07\n",
      "Image 166/200 (4746) | Time/iter: 4.19s | ETA: 00:02:22\n",
      "Image 167/200 (4767) | Time/iter: 3.89s | ETA: 00:02:08\n",
      "Image 168/200 (4788) | Time/iter: 5.06s | ETA: 00:02:41\n",
      "Image 169/200 (4796) | Time/iter: 4.40s | ETA: 00:02:16\n",
      "Image 170/200 (4823) | Time/iter: 7.19s | ETA: 00:03:35\n",
      "Image 171/200 (4825) | Time/iter: 7.45s | ETA: 00:03:35\n",
      "Image 172/200 (4856) | Time/iter: 7.13s | ETA: 00:03:19\n",
      "Image 173/200 (4934) | Time/iter: 10.51s | ETA: 00:04:43\n",
      "Image 174/200 (4991) | Time/iter: 8.13s | ETA: 00:03:31\n",
      "Image 175/200 (5049) | Time/iter: 7.88s | ETA: 00:03:17\n",
      "Image 176/200 (5059) | Time/iter: 3.93s | ETA: 00:01:34\n",
      "Image 177/200 (5062) | Time/iter: 10.65s | ETA: 00:04:04\n",
      "Image 178/200 (5214) | Time/iter: 7.29s | ETA: 00:02:40\n",
      "Image 179/200 (5234) | Time/iter: 7.19s | ETA: 00:02:30\n",
      "Image 180/200 (5249) | Time/iter: 7.19s | ETA: 00:02:23\n",
      "Image 181/200 (5253) | Time/iter: 4.76s | ETA: 00:01:30\n",
      "Image 182/200 (5254) | Time/iter: 7.85s | ETA: 00:02:21\n",
      "Image 183/200 (5285) | Time/iter: 8.04s | ETA: 00:02:16\n",
      "Image 184/200 (5360) | Time/iter: 3.91s | ETA: 00:01:02\n",
      "Image 185/200 (5382) | Time/iter: 4.41s | ETA: 00:01:06\n",
      "Image 186/200 (5383) | Time/iter: 7.17s | ETA: 00:01:40\n",
      "Image 187/200 (5460) | Time/iter: 4.39s | ETA: 00:00:57\n",
      "Image 188/200 (5568) | Time/iter: 3.94s | ETA: 00:00:47\n",
      "Image 189/200 (5589) | Time/iter: 7.21s | ETA: 00:01:19\n",
      "Image 190/200 (5593) | Time/iter: 3.90s | ETA: 00:00:38\n",
      "Image 191/200 (5611) | Time/iter: 7.26s | ETA: 00:01:05\n",
      "Image 192/200 (5617) | Time/iter: 4.36s | ETA: 00:00:34\n",
      "Image 193/200 (5652) | Time/iter: 19.58s | ETA: 00:02:17\n",
      "Image 194/200 (5668) | Time/iter: 7.15s | ETA: 00:00:42\n",
      "Image 195/200 (5673) | Time/iter: 4.43s | ETA: 00:00:22\n",
      "Image 196/200 (5693) | Time/iter: 7.25s | ETA: 00:00:29\n",
      "Image 197/200 (5695) | Time/iter: 5.18s | ETA: 00:00:15\n",
      "Image 198/200 (5698) | Time/iter: 12.18s | ETA: 00:00:24\n",
      "Image 199/200 (5708) | Time/iter: 7.95s | ETA: 00:00:07\n",
      "Image 200/200 (5721) | Time/iter: 4.53s | ETA: 00:00:00\n",
      "ðŸŽ‰ IIW reflectance outputs saved in: E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\smoothing_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "# IIW Dataset paths\n",
    "iiw_input_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\smoothing_input\"\n",
    "iiw_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\smoothing_output\"\n",
    "os.makedirs(iiw_output_dir, exist_ok=True)\n",
    "\n",
    "# --- Prevent accidental concurrent double-run (which duplicates output lines) ---\n",
    "if globals().get('_IIW_PROCESSING_ACTIVE', False):\n",
    "    raise RuntimeError(\"IIW processing already running in this kernel. Wait for it to finish or restart kernel.\")\n",
    "_IIW_PROCESSING_ACTIVE = True\n",
    "\n",
    "# --- Ensure dependencies from previous cell are available after a restart ---\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "try:\n",
    "    load_image\n",
    "except NameError:\n",
    "    from chrislib.data_util import load_image  # Will raise if unavailable\n",
    "try:\n",
    "    view\n",
    "except NameError:\n",
    "    from chrislib.general import view, invert\n",
    "try:\n",
    "    run_pipeline\n",
    "except NameError:\n",
    "    from intrinsic.pipeline import run_pipeline\n",
    "if 'models' not in globals():\n",
    "    _IIW_PROCESSING_ACTIVE = False\n",
    "    raise RuntimeError(\"'models' dict missing. Execute the model loading cell above.\")\n",
    "if 'device' not in globals():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def numeric_sort_key(path):\n",
    "    \"\"\"Return (leading_number, lowercase_name) for consistent numeric ordering.\"\"\"\n",
    "    fname = os.path.splitext(os.path.basename(path))[0]\n",
    "    m = re.match(r'^(\\d+)', fname)\n",
    "    if m:\n",
    "        return (int(m.group(1)), fname.lower())\n",
    "    return (float('inf'), fname.lower())\n",
    "\n",
    "# Collect images once (case-insensitive filtering) using os.listdir to avoid duplicate glob matches\n",
    "image_files = []\n",
    "for f in os.listdir(iiw_input_dir):\n",
    "    fl = f.lower()\n",
    "    if fl.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_files.append(os.path.join(iiw_input_dir, f))\n",
    "\n",
    "# Sort and take only the first N images\n",
    "iiw_image_paths = sorted(image_files, key=numeric_sort_key)\n",
    "MAX_TO_PROCESS = 1000\n",
    "batch_paths = iiw_image_paths[:MAX_TO_PROCESS]\n",
    "\n",
    "print(f\"Found {len(iiw_image_paths)} images in {iiw_input_dir}\")\n",
    "print(f\"Processing first {len(batch_paths)} images in numeric order\")\n",
    "if batch_paths:\n",
    "    preview = [os.path.splitext(os.path.basename(p))[0] for p in batch_paths[:15]]\n",
    "    print(\"Numeric processing order preview (first 15):\", preview)\n",
    "\n",
    "total_images = len(batch_paths)\n",
    "start_time = time.time()\n",
    "for idx, img_path in enumerate(batch_paths, 1):\n",
    "    iter_start = time.time()\n",
    "    image = load_image(img_path)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "    alb = view(results[\"hr_alb\"])\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(iiw_output_dir, f\"{fname}_reflectance.png\")\n",
    "    imwrite(out_path, alb_save)\n",
    "    iter_time = time.time() - iter_start\n",
    "    remaining = (total_images - idx) * iter_time\n",
    "    eta = time.strftime('%H:%M:%S', time.gmtime(max(0, remaining)))\n",
    "    print(f\"Image {idx}/{total_images} ({fname}) | Time/iter: {iter_time:.2f}s | ETA: {eta}\")\n",
    "\n",
    "print(f\"ðŸŽ‰ IIW reflectance outputs saved in: {iiw_output_dir}\")\n",
    "_IIW_PROCESSING_ACTIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4698fb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [03:14<00:00,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your Synthetic Dense dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a775370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_22144\\2379452691.py:54: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_22144\\2379452691.py:55: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARAP Albedo: LMSE=0.0804, RMSE=0.2416, SSIM=0.6279\n",
      "ARAP Shading: LMSE=0.1034, RMSE=0.2829, SSIM=0.5256\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ARAP paths (use raw strings to avoid escape issues)\n",
    "arap_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_output\\albedo\"\n",
    "arap_pred_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\smoothing_output\\shading\"\n",
    "arap_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Albedo\"\n",
    "arap_gt_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Shading\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    # Drop alpha if present, then convert to grayscale and squeeze to 2D\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    # Ensure odd window <= min(h, w); fallback to 3 if needed\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3:\n",
    "        win = 3\n",
    "    if win % 2 == 0:\n",
    "        win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def compute_metrics(pred_dir, gt_dir, metric_type):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if metric_type == 'alb' and (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            base_name = fname.rsplit('_alb', 1)[0]\n",
    "            gt_suffix = '_albedo'\n",
    "        elif metric_type == 'shd' and (low.endswith('_shd.png') or low.endswith('_shd.jpg') or low.endswith('_shd.jpeg')):\n",
    "            base_name = fname.rsplit('_shd', 1)[0]\n",
    "            gt_suffix = '_shading'\n",
    "        else:\n",
    "            print(f\"Skipping {fname} (unexpected suffix)\")\n",
    "            continue\n",
    "        gt_file = None\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            candidate = f\"{base_name}{gt_suffix}{ext}\"\n",
    "            if os.path.exists(os.path.join(gt_dir, candidate)):\n",
    "                gt_file = candidate\n",
    "                break\n",
    "        if gt_file is None:\n",
    "            print(f\"No GT found for {fname}\")\n",
    "            continue\n",
    "        pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
    "        gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n",
    "        # Grayscale first, strictly 2D\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        # Resize only grayscale to match shapes\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        # LMSE implementation on grayscale\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                # If image too small for one window, fallback to global MSE\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gt_patch = gt[i:i+window_size, j:j+window_size]\n",
    "                    pred_patch = pred[i:i+window_size, j:j+window_size]\n",
    "                    mse = np.mean((gt_patch - pred_patch) ** 2)\n",
    "                    errors.append(mse)\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_val = lmse(gt_gray, pred_gray, window_size=20, window_shift=10)\n",
    "        rmse_val = float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2)))\n",
    "        ssim_val = float(safe_ssim(pred_gray, gt_gray))\n",
    "        lmse_vals.append(lmse_val)\n",
    "        rmse_vals.append(rmse_val)\n",
    "        ssim_vals.append(ssim_val)\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "# Compute metrics for albedo\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_metrics(arap_pred_albedo_dir, arap_gt_albedo_dir, metric_type='alb')\n",
    "print(f\"ARAP Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")\n",
    "\n",
    "# Compute metrics for shading\n",
    "lmse_shd, rmse_shd, ssim_shd = compute_metrics(arap_pred_shading_dir, arap_gt_shading_dir, metric_type='shd')\n",
    "print(f\"ARAP Shading: LMSE={lmse_shd:.4f}, RMSE={rmse_shd:.4f}, SSIM={ssim_shd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca45624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014: WHDR=0.6368\n",
      "1068: WHDR=0.1691\n",
      "1094: WHDR=0.0807\n",
      "1118: WHDR=0.2909\n",
      "1127: WHDR=0.1194\n",
      "1141: WHDR=0.3184\n",
      "1143: WHDR=0.2339\n",
      "116: WHDR=0.0798\n",
      "1195: WHDR=0.1392\n",
      "119: WHDR=0.3020\n",
      "1206: WHDR=0.2529\n",
      "1141: WHDR=0.3184\n",
      "1143: WHDR=0.2339\n",
      "116: WHDR=0.0798\n",
      "1195: WHDR=0.1392\n",
      "119: WHDR=0.3020\n",
      "1206: WHDR=0.2529\n",
      "1221: WHDR=0.4122\n",
      "1226: WHDR=0.2898\n",
      "1232: WHDR=0.5204\n",
      "1245: WHDR=0.0783\n",
      "1302: WHDR=0.2952\n",
      "1376: WHDR=0.2843\n",
      "1221: WHDR=0.4122\n",
      "1226: WHDR=0.2898\n",
      "1232: WHDR=0.5204\n",
      "1245: WHDR=0.0783\n",
      "1302: WHDR=0.2952\n",
      "1376: WHDR=0.2843\n",
      "141: WHDR=0.0575\n",
      "1453: WHDR=0.1183\n",
      "1694: WHDR=0.1144\n",
      "176: WHDR=0.1394\n",
      "180: WHDR=0.2240\n",
      "182: WHDR=0.2793\n",
      "141: WHDR=0.0575\n",
      "1453: WHDR=0.1183\n",
      "1694: WHDR=0.1144\n",
      "176: WHDR=0.1394\n",
      "180: WHDR=0.2240\n",
      "182: WHDR=0.2793\n",
      "1934: WHDR=0.1525\n",
      "2066: WHDR=0.2593\n",
      "2200: WHDR=0.2581\n",
      "2232: WHDR=0.1928\n",
      "2237: WHDR=0.1886\n",
      "1934: WHDR=0.1525\n",
      "2066: WHDR=0.2593\n",
      "2200: WHDR=0.2581\n",
      "2232: WHDR=0.1928\n",
      "2237: WHDR=0.1886\n",
      "2254: WHDR=0.1358\n",
      "227: WHDR=0.1206\n",
      "2301: WHDR=0.0841\n",
      "2305: WHDR=0.2504\n",
      "2311: WHDR=0.1414\n",
      "2254: WHDR=0.1358\n",
      "227: WHDR=0.1206\n",
      "2301: WHDR=0.0841\n",
      "2305: WHDR=0.2504\n",
      "2311: WHDR=0.1414\n",
      "2324: WHDR=0.4132\n",
      "2349: WHDR=0.1830\n",
      "2352: WHDR=0.2015\n",
      "2355: WHDR=0.2483\n",
      "2377: WHDR=0.2975\n",
      "239: WHDR=0.1249\n",
      "2324: WHDR=0.4132\n",
      "2349: WHDR=0.1830\n",
      "2352: WHDR=0.2015\n",
      "2355: WHDR=0.2483\n",
      "2377: WHDR=0.2975\n",
      "239: WHDR=0.1249\n",
      "2406: WHDR=0.2056\n",
      "245: WHDR=0.1729\n",
      "2466: WHDR=0.2245\n",
      "2471: WHDR=0.2646\n",
      "2476: WHDR=0.3113\n",
      "2406: WHDR=0.2056\n",
      "245: WHDR=0.1729\n",
      "2466: WHDR=0.2245\n",
      "2471: WHDR=0.2646\n",
      "2476: WHDR=0.3113\n",
      "2504: WHDR=0.2539\n",
      "253: WHDR=0.1293\n",
      "2545: WHDR=0.1285\n",
      "2547: WHDR=0.1996\n",
      "2548: WHDR=0.3274\n",
      "257: WHDR=0.1791\n",
      "2504: WHDR=0.2539\n",
      "253: WHDR=0.1293\n",
      "2545: WHDR=0.1285\n",
      "2547: WHDR=0.1996\n",
      "2548: WHDR=0.3274\n",
      "257: WHDR=0.1791\n",
      "2598: WHDR=0.1300\n",
      "2602: WHDR=0.5890\n",
      "2606: WHDR=0.2979\n",
      "2615: WHDR=0.1997\n",
      "2620: WHDR=0.4313\n",
      "2598: WHDR=0.1300\n",
      "2602: WHDR=0.5890\n",
      "2606: WHDR=0.2979\n",
      "2615: WHDR=0.1997\n",
      "2620: WHDR=0.4313\n",
      "262: WHDR=0.6044\n",
      "2636: WHDR=0.2703\n",
      "2715: WHDR=0.2862\n",
      "2727: WHDR=0.2153\n",
      "2758: WHDR=0.4893\n",
      "262: WHDR=0.6044\n",
      "2636: WHDR=0.2703\n",
      "2715: WHDR=0.2862\n",
      "2727: WHDR=0.2153\n",
      "2758: WHDR=0.4893\n",
      "277: WHDR=0.2058\n",
      "2789: WHDR=0.0823\n",
      "2828: WHDR=0.4156\n",
      "2894: WHDR=0.2576\n",
      "277: WHDR=0.2058\n",
      "2789: WHDR=0.0823\n",
      "2828: WHDR=0.4156\n",
      "2894: WHDR=0.2576\n",
      "2910: WHDR=0.2818\n",
      "2970: WHDR=0.3211\n",
      "2998: WHDR=0.2031\n",
      "2910: WHDR=0.2818\n",
      "2970: WHDR=0.3211\n",
      "2998: WHDR=0.2031\n",
      "3044: WHDR=0.1483\n",
      "3072: WHDR=0.1829\n",
      "3136: WHDR=0.3341\n",
      "3199: WHDR=0.2164\n",
      "3219: WHDR=0.1123\n",
      "3044: WHDR=0.1483\n",
      "3072: WHDR=0.1829\n",
      "3136: WHDR=0.3341\n",
      "3199: WHDR=0.2164\n",
      "3219: WHDR=0.1123\n",
      "3221: WHDR=0.0606\n",
      "3240: WHDR=0.4260\n",
      "3246: WHDR=0.0816\n",
      "3247: WHDR=0.2245\n",
      "3254: WHDR=0.2305\n",
      "3305: WHDR=0.2213\n",
      "3221: WHDR=0.0606\n",
      "3240: WHDR=0.4260\n",
      "3246: WHDR=0.0816\n",
      "3247: WHDR=0.2245\n",
      "3254: WHDR=0.2305\n",
      "3305: WHDR=0.2213\n",
      "3308: WHDR=0.0625\n",
      "3353: WHDR=0.0818\n",
      "3363: WHDR=0.1905\n",
      "3392: WHDR=0.2427\n",
      "3308: WHDR=0.0625\n",
      "3353: WHDR=0.0818\n",
      "3363: WHDR=0.1905\n",
      "3392: WHDR=0.2427\n",
      "3400: WHDR=0.1303\n",
      "3403: WHDR=0.2839\n",
      "3438: WHDR=0.1693\n",
      "3446: WHDR=0.1235\n",
      "3400: WHDR=0.1303\n",
      "3403: WHDR=0.2839\n",
      "3438: WHDR=0.1693\n",
      "3446: WHDR=0.1235\n",
      "3463: WHDR=0.2170\n",
      "3466: WHDR=0.2341\n",
      "3544: WHDR=0.3368\n",
      "3592: WHDR=0.2661\n",
      "3463: WHDR=0.2170\n",
      "3466: WHDR=0.2341\n",
      "3544: WHDR=0.3368\n",
      "3592: WHDR=0.2661\n",
      "3625: WHDR=0.4531\n",
      "3642: WHDR=0.1251\n",
      "3679: WHDR=0.1493\n",
      "3701: WHDR=0.2875\n",
      "370: WHDR=0.2168\n",
      "3625: WHDR=0.4531\n",
      "3642: WHDR=0.1251\n",
      "3679: WHDR=0.1493\n",
      "3701: WHDR=0.2875\n",
      "370: WHDR=0.2168\n",
      "3715: WHDR=0.2241\n",
      "3730: WHDR=0.2249\n",
      "3773: WHDR=0.1593\n",
      "3859: WHDR=0.3434\n",
      "3715: WHDR=0.2241\n",
      "3730: WHDR=0.2249\n",
      "3773: WHDR=0.1593\n",
      "3859: WHDR=0.3434\n",
      "3864: WHDR=0.2045\n",
      "3877: WHDR=0.1475\n",
      "3916: WHDR=0.1050\n",
      "3932: WHDR=0.1748\n",
      "3958: WHDR=0.3829\n",
      "3864: WHDR=0.2045\n",
      "3877: WHDR=0.1475\n",
      "3916: WHDR=0.1050\n",
      "3932: WHDR=0.1748\n",
      "3958: WHDR=0.3829\n",
      "4023: WHDR=0.1656\n",
      "4032: WHDR=0.1271\n",
      "4037: WHDR=0.2302\n",
      "4057: WHDR=0.1973\n",
      "4131: WHDR=0.3090\n",
      "4023: WHDR=0.1656\n",
      "4032: WHDR=0.1271\n",
      "4037: WHDR=0.2302\n",
      "4057: WHDR=0.1973\n",
      "4131: WHDR=0.3090\n",
      "4136: WHDR=0.2414\n",
      "417: WHDR=0.2773\n",
      "4203: WHDR=0.3237\n",
      "4217: WHDR=0.4962\n",
      "4136: WHDR=0.2414\n",
      "417: WHDR=0.2773\n",
      "4203: WHDR=0.3237\n",
      "4217: WHDR=0.4962\n",
      "4259: WHDR=0.5992\n",
      "4264: WHDR=0.2508\n",
      "4269: WHDR=0.3293\n",
      "4287: WHDR=0.2437\n",
      "4259: WHDR=0.5992\n",
      "4264: WHDR=0.2508\n",
      "4269: WHDR=0.3293\n",
      "4287: WHDR=0.2437\n",
      "4302: WHDR=0.2096\n",
      "434: WHDR=0.2909\n",
      "4392: WHDR=0.2262\n",
      "4440: WHDR=0.1394\n",
      "4495: WHDR=0.3398\n",
      "4302: WHDR=0.2096\n",
      "434: WHDR=0.2909\n",
      "4392: WHDR=0.2262\n",
      "4440: WHDR=0.1394\n",
      "4495: WHDR=0.3398\n",
      "4496: WHDR=0.5681\n",
      "4542: WHDR=0.3110\n",
      "4574: WHDR=0.3676\n",
      "4593: WHDR=0.4386\n",
      "4496: WHDR=0.5681\n",
      "4542: WHDR=0.3110\n",
      "4574: WHDR=0.3676\n",
      "4593: WHDR=0.4386\n",
      "4627: WHDR=0.2739\n",
      "4687: WHDR=0.2788\n",
      "4746: WHDR=0.1912\n",
      "4767: WHDR=0.1916\n",
      "4788: WHDR=0.4217\n",
      "4796: WHDR=0.2642\n",
      "4627: WHDR=0.2739\n",
      "4687: WHDR=0.2788\n",
      "4746: WHDR=0.1912\n",
      "4767: WHDR=0.1916\n",
      "4788: WHDR=0.4217\n",
      "4796: WHDR=0.2642\n",
      "4823: WHDR=0.1939\n",
      "4825: WHDR=0.5322\n",
      "4856: WHDR=0.3434\n",
      "491: WHDR=0.3261\n",
      "4823: WHDR=0.1939\n",
      "4825: WHDR=0.5322\n",
      "4856: WHDR=0.3434\n",
      "491: WHDR=0.3261\n",
      "4934: WHDR=0.3679\n",
      "498: WHDR=0.2689\n",
      "4991: WHDR=0.4006\n",
      "502: WHDR=0.0329\n",
      "5049: WHDR=0.1883\n",
      "4934: WHDR=0.3679\n",
      "498: WHDR=0.2689\n",
      "4991: WHDR=0.4006\n",
      "502: WHDR=0.0329\n",
      "5049: WHDR=0.1883\n",
      "504: WHDR=0.5151\n",
      "5059: WHDR=0.2399\n",
      "5062: WHDR=0.3668\n",
      "5214: WHDR=0.1974\n",
      "504: WHDR=0.5151\n",
      "5059: WHDR=0.2399\n",
      "5062: WHDR=0.3668\n",
      "5214: WHDR=0.1974\n",
      "5234: WHDR=0.1792\n",
      "5249: WHDR=0.3418\n",
      "5253: WHDR=0.2970\n",
      "5254: WHDR=0.2336\n",
      "527: WHDR=0.2215\n",
      "5234: WHDR=0.1792\n",
      "5249: WHDR=0.3418\n",
      "5253: WHDR=0.2970\n",
      "5254: WHDR=0.2336\n",
      "527: WHDR=0.2215\n",
      "5285: WHDR=0.4592\n",
      "5360: WHDR=0.1009\n",
      "5382: WHDR=0.1825\n",
      "5383: WHDR=0.3559\n",
      "5460: WHDR=0.1272\n",
      "5285: WHDR=0.4592\n",
      "5360: WHDR=0.1009\n",
      "5382: WHDR=0.1825\n",
      "5383: WHDR=0.3559\n",
      "5460: WHDR=0.1272\n",
      "54: WHDR=0.2188\n",
      "5568: WHDR=0.2314\n",
      "5589: WHDR=0.0535\n",
      "5593: WHDR=0.2694\n",
      "560: WHDR=0.1767\n",
      "54: WHDR=0.2188\n",
      "5568: WHDR=0.2314\n",
      "5589: WHDR=0.0535\n",
      "5593: WHDR=0.2694\n",
      "560: WHDR=0.1767\n",
      "5611: WHDR=0.2027\n",
      "5617: WHDR=0.2830\n",
      "5652: WHDR=0.5043\n",
      "5668: WHDR=0.3255\n",
      "5611: WHDR=0.2027\n",
      "5617: WHDR=0.2830\n",
      "5652: WHDR=0.5043\n",
      "5668: WHDR=0.3255\n",
      "5673: WHDR=0.0803\n",
      "5693: WHDR=0.3119\n",
      "5695: WHDR=0.2883\n",
      "5698: WHDR=0.2855\n",
      "5673: WHDR=0.0803\n",
      "5693: WHDR=0.3119\n",
      "5695: WHDR=0.2883\n",
      "5698: WHDR=0.2855\n",
      "5708: WHDR=0.1271\n",
      "5721: WHDR=0.2438\n",
      "579: WHDR=0.1044\n",
      "593: WHDR=0.2277\n",
      "594: WHDR=0.2412\n",
      "5708: WHDR=0.1271\n",
      "5721: WHDR=0.2438\n",
      "579: WHDR=0.1044\n",
      "593: WHDR=0.2277\n",
      "594: WHDR=0.2412\n",
      "597: WHDR=0.0463\n",
      "611: WHDR=0.4708\n",
      "613: WHDR=0.2926\n",
      "627: WHDR=0.1193\n",
      "633: WHDR=0.2256\n",
      "597: WHDR=0.0463\n",
      "611: WHDR=0.4708\n",
      "613: WHDR=0.2926\n",
      "627: WHDR=0.1193\n",
      "633: WHDR=0.2256\n",
      "63: WHDR=0.1354\n",
      "653: WHDR=0.2897\n",
      "657: WHDR=0.1513\n",
      "662: WHDR=0.2674\n",
      "686: WHDR=0.2408\n",
      "749: WHDR=0.1983\n",
      "63: WHDR=0.1354\n",
      "653: WHDR=0.2897\n",
      "657: WHDR=0.1513\n",
      "662: WHDR=0.2674\n",
      "686: WHDR=0.2408\n",
      "749: WHDR=0.1983\n",
      "760: WHDR=0.1186\n",
      "771: WHDR=0.1520\n",
      "791: WHDR=0.3453\n",
      "815: WHDR=0.2282\n",
      "821: WHDR=0.1735\n",
      "827: WHDR=0.2056\n",
      "760: WHDR=0.1186\n",
      "771: WHDR=0.1520\n",
      "791: WHDR=0.3453\n",
      "815: WHDR=0.2282\n",
      "821: WHDR=0.1735\n",
      "827: WHDR=0.2056\n",
      "844: WHDR=0.4292\n",
      "845: WHDR=0.1615\n",
      "856: WHDR=0.1407\n",
      "859: WHDR=0.2290\n",
      "860: WHDR=0.0773\n",
      "876: WHDR=0.2908\n",
      "844: WHDR=0.4292\n",
      "845: WHDR=0.1615\n",
      "856: WHDR=0.1407\n",
      "859: WHDR=0.2290\n",
      "860: WHDR=0.0773\n",
      "876: WHDR=0.2908\n",
      "918: WHDR=0.2825\n",
      "922: WHDR=0.1900\n",
      "952: WHDR=0.2661\n",
      "953: WHDR=0.1556\n",
      "\n",
      "Evaluated 200 images. Mean WHDR = 0.2449\n",
      "918: WHDR=0.2825\n",
      "922: WHDR=0.1900\n",
      "952: WHDR=0.2661\n",
      "953: WHDR=0.1556\n",
      "\n",
      "Evaluated 200 images. Mean WHDR = 0.2449\n"
     ]
    }
   ],
   "source": [
    "# Compute WHDR for IIW outputs using attached whdr logic (Python 3 safe)\n",
    "import os, json, sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Paths (raw strings for Windows)\n",
    "iiW_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\smoothing_output\"\n",
    "iiW_annotations_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\annotations\"\n",
    "\n",
    "# --- WHDR utilities (ported to Py3, in-notebook) ---\n",
    "def srgb_to_rgb(srgb):\n",
    "    srgb = np.asarray(srgb, dtype=np.float32)\n",
    "    ret = np.zeros_like(srgb, dtype=np.float32)\n",
    "    idx0 = srgb <= 0.04045\n",
    "    idx1 = ~idx0\n",
    "    ret[idx0] = srgb[idx0] / 12.92\n",
    "    ret[idx1] = np.power((srgb[idx1] + 0.055) / 1.055, 2.4)\n",
    "    return ret\n",
    "\n",
    "def load_image_linear(filename, is_srgb=True):\n",
    "    if not filename:\n",
    "        raise ValueError(\"Empty filename\")\n",
    "    image = np.asarray(Image.open(filename)).astype(np.float32) / 255.0\n",
    "    if is_srgb:\n",
    "        return srgb_to_rgb(image)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def compute_whdr(reflectance, judgements, delta=0.10):\n",
    "    points = judgements['intrinsic_points']\n",
    "    comparisons = judgements['intrinsic_comparisons']\n",
    "    id_to_points = {p['id']: p for p in points}\n",
    "    rows, cols = reflectance.shape[0:2]\n",
    "\n",
    "    error_sum = 0.0\n",
    "    weight_sum = 0.0\n",
    "\n",
    "    for c in comparisons:\n",
    "        darker = c.get('darker')\n",
    "        if darker not in ('1', '2', 'E'):\n",
    "            continue\n",
    "\n",
    "        weight = c.get('darker_score')\n",
    "        if weight is None or weight <= 0:\n",
    "            continue\n",
    "\n",
    "        p1 = id_to_points.get(c['point1'])\n",
    "        p2 = id_to_points.get(c['point2'])\n",
    "        if p1 is None or p2 is None:\n",
    "            continue\n",
    "        if not p1.get('opaque', False) or not p2.get('opaque', False):\n",
    "            continue\n",
    "\n",
    "        y1 = min(rows - 1, max(0, int(p1['y'] * rows)))\n",
    "        x1 = min(cols - 1, max(0, int(p1['x'] * cols)))\n",
    "        y2 = min(rows - 1, max(0, int(p2['y'] * rows)))\n",
    "        x2 = min(cols - 1, max(0, int(p2['x'] * cols)))\n",
    "\n",
    "        l1 = max(1e-10, float(np.mean(reflectance[y1, x1, ...])))\n",
    "        l2 = max(1e-10, float(np.mean(reflectance[y2, x2, ...])))\n",
    "\n",
    "        if l2 / l1 > 1.0 + delta:\n",
    "            alg_darker = '1'\n",
    "        elif l1 / l2 > 1.0 + delta:\n",
    "            alg_darker = '2'\n",
    "        else:\n",
    "            alg_darker = 'E'\n",
    "\n",
    "        if darker != alg_darker:\n",
    "            error_sum += weight\n",
    "        weight_sum += weight\n",
    "\n",
    "    if weight_sum > 0:\n",
    "        return error_sum / weight_sum\n",
    "    return None\n",
    "\n",
    "# --- Batch evaluation over available outputs ---\n",
    "# We only evaluate files present in the output directory; we expect names like 1014_reflectance.png\n",
    "valid_exts = ('.png', '.jpg', '.jpeg')\n",
    "reflectance_files = [f for f in os.listdir(iiW_output_dir) if f.lower().endswith(valid_exts) and '_reflectance' in f]\n",
    "reflectance_files.sort()\n",
    "\n",
    "results = []\n",
    "for f in reflectance_files:\n",
    "    stem = os.path.splitext(f)[0]\n",
    "    # Expect pattern <photoid>_reflectance\n",
    "    if not stem.endswith('_reflectance'):\n",
    "        continue\n",
    "    photo_id = stem.rsplit('_reflectance', 1)[0]\n",
    "    json_path = os.path.join(iiW_annotations_dir, f\"{photo_id}.json\")\n",
    "    img_path = os.path.join(iiW_output_dir, f)\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Skipping {f}: missing annotations {photo_id}.json\")\n",
    "        continue\n",
    "    try:\n",
    "        refl = load_image_linear(img_path, is_srgb=True)  # saved PNGs are sRGB; convert to linear\n",
    "        with open(json_path, 'r') as jf:\n",
    "            judg = json.load(jf)\n",
    "        score = compute_whdr(refl, judg, delta=0.10)\n",
    "        if score is None:\n",
    "            print(f\"{photo_id}: no valid judgements; WHDR=None\")\n",
    "            continue\n",
    "        results.append((photo_id, score))\n",
    "        print(f\"{photo_id}: WHDR={score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{photo_id}: error computing WHDR -> {e}\")\n",
    "\n",
    "if results:\n",
    "    mean_whdr = float(np.mean([s for _, s in results]))\n",
    "    print(f\"\\nEvaluated {len(results)} images. Mean WHDR = {mean_whdr:.4f}\")\n",
    "else:\n",
    "    print(\"No WHDR scores computed. Ensure output images and matching JSONs exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf3f6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_22144\\512368895.py:61: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_22144\\512368895.py:62: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(gt_path).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 22 pairs; Missing GT for 1 files.\n",
      "Synthetic Dense Albedo: LMSE=0.0882, RMSE=0.2888, SSIM=0.5333\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Dense Albedo Metrics Only (LMSE, RMSE, SSIM) with robust GT matching\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Synthetic Dense paths (update if your dataset root differs)\n",
    "sd_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\smoothing_output\\albedo\"\n",
    "sd_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\Gt_albedo\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3: win = 3\n",
    "    if win % 2 == 0: win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def find_gt_file(gt_dir: str, stem: str):\n",
    "    candidates = []\n",
    "    # Common direct patterns\n",
    "    for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "        candidates.append(f\"{stem}_albedo{ext}\")\n",
    "        candidates.append(f\"{stem}{ext}\")\n",
    "    for c in candidates:\n",
    "        p = os.path.join(gt_dir, c)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    # Fallback: scan directory for files that start with stem and contain 'alb' or 'albedo'\n",
    "    low_stem = stem.lower()\n",
    "    for f in os.listdir(gt_dir):\n",
    "        fl = f.lower()\n",
    "        if (fl.startswith(low_stem)) and (('albedo' in fl) or ('alb' in fl)) and fl.endswith(tuple(['.png','.jpg','.jpeg','.PNG','.JPG','.JPEG'])):\n",
    "            return os.path.join(gt_dir, f)\n",
    "    return None\n",
    "\n",
    "def compute_albedo_metrics(pred_dir, gt_dir):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if not pred_files:\n",
    "        print(f\"âš  No predicted albedo files found in {pred_dir}\")\n",
    "        return None, None, None\n",
    "    matched = 0; missing = 0\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if not (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            continue\n",
    "        stem = fname.rsplit('_alb', 1)[0]\n",
    "        gt_path = find_gt_file(gt_dir, stem)\n",
    "        if gt_path is None:\n",
    "            missing += 1\n",
    "            continue\n",
    "        pred_path = os.path.join(pred_dir, fname)\n",
    "        pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
    "        gt_img = imread(gt_path).astype(np.float32) / 255.0\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gpatch = gt[i:i+window_size, j:j+window_size]\n",
    "                    ppatch = pred[i:i+window_size, j:j+window_size]\n",
    "                    errors.append(np.mean((gpatch - ppatch) ** 2))\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_vals.append(lmse(gt_gray, pred_gray))\n",
    "        rmse_vals.append(float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2))))\n",
    "        ssim_vals.append(float(safe_ssim(pred_gray, gt_gray)))\n",
    "        matched += 1\n",
    "    if matched == 0:\n",
    "        print(f\"âš  No GT matches found in {gt_dir} for stems of predictions in {pred_dir}. Check naming.\")\n",
    "        if missing > 0:\n",
    "            print(f\"   Missing GT for {missing} predicted files.\")\n",
    "        return None, None, None\n",
    "    print(f\"Matched {matched} pairs; Missing GT for {missing} files.\")\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_albedo_metrics(sd_pred_albedo_dir, sd_gt_albedo_dir)\n",
    "if lmse_alb is None:\n",
    "    print(\"Synthetic Dense Albedo: metrics unavailable (no matched pairs).\")\n",
    "else:\n",
    "    print(f\"Synthetic Dense Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
