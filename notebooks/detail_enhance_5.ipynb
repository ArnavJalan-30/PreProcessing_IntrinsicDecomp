{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847d397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\COLLEGE MATERIAL\\Ordinal_Shading\n"
     ]
    }
   ],
   "source": [
    "%cd E:\\COLLEGE MATERIAL\\Ordinal_Shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1eb199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddca1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Ensure local imports work\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "\n",
    "from chrislib.general import view, invert\n",
    "from chrislib.data_util import load_image\n",
    "from intrinsic.pipeline import run_pipeline\n",
    "from altered_midas.midas_net import MidasNet\n",
    "from altered_midas.midas_net_custom import MidasNet_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2af068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading models manually from local weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n",
      "Using cache found in C:\\Users\\Arnav Jalan/.cache\\torch\\hub\\facebookresearch_WSL-Images_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models loaded\n"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------\n",
    "# MANUAL MODEL LOADING (local weights)\n",
    "# -----------------------------\n",
    "print(\"ðŸ“¦ Loading models manually from local weights...\")\n",
    "model_dir = \"models\"\n",
    "ord_model = MidasNet()\n",
    "ord_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_0_v21.pt\"), map_location=device))\n",
    "ord_model.eval()\n",
    "ord_model = ord_model.to(device)\n",
    "\n",
    "iid_model = MidasNet_small(exportable=False, input_channels=5, output_channels=1)\n",
    "iid_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_1_v21.pt\"), map_location=device))\n",
    "iid_model.eval()\n",
    "iid_model = iid_model.to(device)\n",
    "\n",
    "col_model = MidasNet(activation='sigmoid', input_channels=7, output_channels=2)\n",
    "col_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_2_v21.pt\"), map_location=device))\n",
    "col_model.eval()\n",
    "col_model = col_model.to(device)\n",
    "\n",
    "alb_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3, last_residual=True)\n",
    "alb_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_3_v21.pt\"), map_location=device))\n",
    "alb_model.eval()\n",
    "alb_model = alb_model.to(device)\n",
    "\n",
    "dif_model = MidasNet(activation='sigmoid', input_channels=9, output_channels=3)\n",
    "dif_model.load_state_dict(torch.load(os.path.join(model_dir, \"stage_4_v21.pt\"), map_location=device))\n",
    "dif_model.eval()\n",
    "dif_model = dif_model.to(device)\n",
    "\n",
    "models = {\n",
    "    \"ord_model\": ord_model,\n",
    "    \"iid_model\": iid_model,\n",
    "    \"col_model\": col_model,\n",
    "    \"alb_model\": alb_model,\n",
    "    \"dif_model\": dif_model,\n",
    "}\n",
    "print(\"âœ… Models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ff4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [06:31<00:00, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your ARAP dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33421e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\detail_enhance_5_input\n",
      "Processing first 200 images in numeric order\n",
      "Numeric processing order preview (first 15): ['54', '63', '116', '119', '141', '176', '180', '182', '227', '239', '245', '253', '257', '262', '277']\n",
      "Image 1/200 (54) | Time/iter: 21.94s | ETA: 01:12:45\n",
      "Image 2/200 (63) | Time/iter: 5.46s | ETA: 00:18:01\n",
      "Image 3/200 (116) | Time/iter: 8.77s | ETA: 00:28:48\n",
      "Image 4/200 (119) | Time/iter: 22.88s | ETA: 01:14:44\n",
      "Image 5/200 (141) | Time/iter: 13.24s | ETA: 00:43:01\n",
      "Image 6/200 (176) | Time/iter: 23.52s | ETA: 01:16:02\n",
      "Image 7/200 (180) | Time/iter: 23.63s | ETA: 01:16:00\n",
      "Image 8/200 (182) | Time/iter: 5.65s | ETA: 00:18:05\n",
      "Image 9/200 (227) | Time/iter: 8.90s | ETA: 00:28:20\n",
      "Image 10/200 (239) | Time/iter: 12.87s | ETA: 00:40:45\n",
      "Image 11/200 (245) | Time/iter: 5.45s | ETA: 00:17:10\n",
      "Image 12/200 (253) | Time/iter: 8.85s | ETA: 00:27:43\n",
      "Image 13/200 (257) | Time/iter: 13.08s | ETA: 00:40:46\n",
      "Image 14/200 (262) | Time/iter: 4.88s | ETA: 00:15:07\n",
      "Image 15/200 (277) | Time/iter: 23.27s | ETA: 01:11:44\n",
      "Image 16/200 (370) | Time/iter: 8.74s | ETA: 00:26:47\n",
      "Image 17/200 (417) | Time/iter: 19.32s | ETA: 00:58:55\n",
      "Image 18/200 (434) | Time/iter: 24.05s | ETA: 01:12:56\n",
      "Image 19/200 (491) | Time/iter: 13.03s | ETA: 00:39:18\n",
      "Image 20/200 (498) | Time/iter: 5.32s | ETA: 00:15:57\n",
      "Image 21/200 (502) | Time/iter: 8.68s | ETA: 00:25:54\n",
      "Image 22/200 (504) | Time/iter: 8.88s | ETA: 00:26:20\n",
      "Image 23/200 (527) | Time/iter: 8.74s | ETA: 00:25:47\n",
      "Image 24/200 (560) | Time/iter: 4.75s | ETA: 00:13:55\n",
      "Image 25/200 (579) | Time/iter: 5.48s | ETA: 00:15:59\n",
      "Image 26/200 (593) | Time/iter: 21.40s | ETA: 01:02:02\n",
      "Image 27/200 (594) | Time/iter: 8.80s | ETA: 00:25:22\n",
      "Image 28/200 (597) | Time/iter: 5.55s | ETA: 00:15:55\n",
      "Image 29/200 (611) | Time/iter: 17.97s | ETA: 00:51:13\n",
      "Image 30/200 (613) | Time/iter: 14.96s | ETA: 00:42:22\n",
      "Image 31/200 (627) | Time/iter: 8.85s | ETA: 00:24:55\n",
      "Image 32/200 (633) | Time/iter: 4.89s | ETA: 00:13:40\n",
      "Image 33/200 (653) | Time/iter: 5.07s | ETA: 00:14:06\n",
      "Image 34/200 (657) | Time/iter: 18.14s | ETA: 00:50:11\n",
      "Image 35/200 (662) | Time/iter: 5.28s | ETA: 00:14:30\n",
      "Image 36/200 (686) | Time/iter: 5.44s | ETA: 00:14:52\n",
      "Image 37/200 (749) | Time/iter: 5.24s | ETA: 00:14:14\n",
      "Image 38/200 (760) | Time/iter: 17.96s | ETA: 00:48:29\n",
      "Image 39/200 (771) | Time/iter: 8.89s | ETA: 00:23:51\n",
      "Image 40/200 (791) | Time/iter: 12.87s | ETA: 00:34:19\n",
      "Image 41/200 (815) | Time/iter: 5.41s | ETA: 00:14:20\n",
      "Image 42/200 (821) | Time/iter: 5.29s | ETA: 00:13:55\n",
      "Image 43/200 (827) | Time/iter: 8.63s | ETA: 00:22:35\n",
      "Image 44/200 (844) | Time/iter: 22.86s | ETA: 00:59:26\n",
      "Image 45/200 (845) | Time/iter: 8.89s | ETA: 00:22:57\n",
      "Image 46/200 (856) | Time/iter: 5.27s | ETA: 00:13:32\n",
      "Image 47/200 (859) | Time/iter: 9.41s | ETA: 00:23:59\n",
      "Image 48/200 (860) | Time/iter: 4.87s | ETA: 00:12:19\n",
      "Image 49/200 (876) | Time/iter: 13.11s | ETA: 00:33:00\n",
      "Image 50/200 (918) | Time/iter: 5.61s | ETA: 00:14:01\n",
      "Image 51/200 (922) | Time/iter: 5.47s | ETA: 00:13:35\n",
      "Image 52/200 (952) | Time/iter: 22.75s | ETA: 00:56:06\n",
      "Image 53/200 (953) | Time/iter: 8.97s | ETA: 00:21:59\n",
      "Image 54/200 (1014) | Time/iter: 26.78s | ETA: 01:05:09\n",
      "Image 55/200 (1068) | Time/iter: 4.87s | ETA: 00:11:46\n",
      "Image 56/200 (1094) | Time/iter: 5.57s | ETA: 00:13:21\n",
      "Image 57/200 (1118) | Time/iter: 9.07s | ETA: 00:21:37\n",
      "Image 58/200 (1127) | Time/iter: 23.04s | ETA: 00:54:31\n",
      "Image 59/200 (1141) | Time/iter: 12.93s | ETA: 00:30:23\n",
      "Image 60/200 (1143) | Time/iter: 6.60s | ETA: 00:15:23\n",
      "Image 61/200 (1195) | Time/iter: 12.87s | ETA: 00:29:48\n",
      "Image 62/200 (1206) | Time/iter: 5.03s | ETA: 00:11:34\n",
      "Image 63/200 (1221) | Time/iter: 5.57s | ETA: 00:12:42\n",
      "Image 64/200 (1226) | Time/iter: 12.67s | ETA: 00:28:42\n",
      "Image 65/200 (1232) | Time/iter: 18.01s | ETA: 00:40:31\n",
      "Image 66/200 (1245) | Time/iter: 9.77s | ETA: 00:21:49\n",
      "Image 67/200 (1302) | Time/iter: 8.86s | ETA: 00:19:38\n",
      "Image 68/200 (1376) | Time/iter: 8.80s | ETA: 00:19:21\n",
      "Image 69/200 (1453) | Time/iter: 12.79s | ETA: 00:27:55\n",
      "Image 70/200 (1694) | Time/iter: 8.69s | ETA: 00:18:49\n",
      "Image 71/200 (1934) | Time/iter: 5.27s | ETA: 00:11:19\n",
      "Image 72/200 (2066) | Time/iter: 8.88s | ETA: 00:18:56\n",
      "Image 73/200 (2200) | Time/iter: 6.37s | ETA: 00:13:28\n",
      "Image 74/200 (2232) | Time/iter: 4.44s | ETA: 00:09:19\n",
      "Image 75/200 (2237) | Time/iter: 13.05s | ETA: 00:27:11\n",
      "Image 76/200 (2254) | Time/iter: 13.43s | ETA: 00:27:45\n",
      "Image 77/200 (2301) | Time/iter: 5.55s | ETA: 00:11:23\n",
      "Image 78/200 (2305) | Time/iter: 12.33s | ETA: 00:25:04\n",
      "Image 79/200 (2311) | Time/iter: 9.43s | ETA: 00:19:00\n",
      "Image 80/200 (2324) | Time/iter: 14.84s | ETA: 00:29:41\n",
      "Image 81/200 (2349) | Time/iter: 23.47s | ETA: 00:46:32\n",
      "Image 82/200 (2352) | Time/iter: 18.46s | ETA: 00:36:17\n",
      "Image 83/200 (2355) | Time/iter: 18.17s | ETA: 00:35:25\n",
      "Image 84/200 (2377) | Time/iter: 24.63s | ETA: 00:47:37\n",
      "Image 85/200 (2406) | Time/iter: 8.96s | ETA: 00:17:10\n",
      "Image 86/200 (2466) | Time/iter: 13.48s | ETA: 00:25:36\n",
      "Image 87/200 (2471) | Time/iter: 17.92s | ETA: 00:33:45\n",
      "Image 88/200 (2476) | Time/iter: 5.63s | ETA: 00:10:30\n",
      "Image 89/200 (2504) | Time/iter: 13.97s | ETA: 00:25:51\n",
      "Image 90/200 (2545) | Time/iter: 5.84s | ETA: 00:10:41\n",
      "Image 91/200 (2547) | Time/iter: 23.54s | ETA: 00:42:45\n",
      "Image 92/200 (2548) | Time/iter: 13.96s | ETA: 00:25:07\n",
      "Image 93/200 (2598) | Time/iter: 22.91s | ETA: 00:40:51\n",
      "Image 94/200 (2602) | Time/iter: 23.47s | ETA: 00:41:28\n",
      "Image 95/200 (2606) | Time/iter: 8.93s | ETA: 00:15:37\n",
      "Image 96/200 (2615) | Time/iter: 13.10s | ETA: 00:22:42\n",
      "Image 97/200 (2620) | Time/iter: 22.62s | ETA: 00:38:50\n",
      "Image 98/200 (2636) | Time/iter: 22.87s | ETA: 00:38:53\n",
      "Image 99/200 (2715) | Time/iter: 22.79s | ETA: 00:38:22\n",
      "Image 100/200 (2727) | Time/iter: 8.57s | ETA: 00:14:17\n",
      "Image 101/200 (2758) | Time/iter: 23.25s | ETA: 00:38:21\n",
      "Image 102/200 (2789) | Time/iter: 23.13s | ETA: 00:37:46\n",
      "Image 103/200 (2828) | Time/iter: 23.03s | ETA: 00:37:13\n",
      "Image 104/200 (2894) | Time/iter: 18.23s | ETA: 00:29:10\n",
      "Image 105/200 (2910) | Time/iter: 18.41s | ETA: 00:29:08\n",
      "Image 106/200 (2970) | Time/iter: 23.15s | ETA: 00:36:15\n",
      "Image 107/200 (2998) | Time/iter: 8.99s | ETA: 00:13:55\n",
      "Image 108/200 (3044) | Time/iter: 12.74s | ETA: 00:19:32\n",
      "Image 109/200 (3072) | Time/iter: 8.93s | ETA: 00:13:32\n",
      "Image 110/200 (3136) | Time/iter: 12.91s | ETA: 00:19:22\n",
      "Image 111/200 (3199) | Time/iter: 13.24s | ETA: 00:19:37\n",
      "Image 112/200 (3219) | Time/iter: 5.67s | ETA: 00:08:18\n",
      "Image 113/200 (3221) | Time/iter: 23.04s | ETA: 00:33:24\n",
      "Image 114/200 (3240) | Time/iter: 14.91s | ETA: 00:21:22\n",
      "Image 115/200 (3246) | Time/iter: 14.73s | ETA: 00:20:52\n",
      "Image 116/200 (3247) | Time/iter: 9.03s | ETA: 00:12:38\n",
      "Image 117/200 (3254) | Time/iter: 17.92s | ETA: 00:24:47\n",
      "Image 118/200 (3305) | Time/iter: 18.28s | ETA: 00:24:58\n",
      "Image 119/200 (3308) | Time/iter: 9.78s | ETA: 00:13:11\n",
      "Image 120/200 (3353) | Time/iter: 27.12s | ETA: 00:36:09\n",
      "Image 121/200 (3363) | Time/iter: 27.05s | ETA: 00:35:36\n",
      "Image 122/200 (3392) | Time/iter: 8.93s | ETA: 00:11:36\n",
      "Image 123/200 (3400) | Time/iter: 5.63s | ETA: 00:07:13\n",
      "Image 124/200 (3403) | Time/iter: 23.12s | ETA: 00:29:17\n",
      "Image 125/200 (3438) | Time/iter: 9.47s | ETA: 00:11:50\n",
      "Image 126/200 (3446) | Time/iter: 8.67s | ETA: 00:10:41\n",
      "Image 127/200 (3463) | Time/iter: 22.91s | ETA: 00:27:52\n",
      "Image 128/200 (3466) | Time/iter: 13.65s | ETA: 00:16:22\n",
      "Image 129/200 (3544) | Time/iter: 23.91s | ETA: 00:28:17\n",
      "Image 130/200 (3592) | Time/iter: 18.00s | ETA: 00:20:59\n",
      "Image 131/200 (3625) | Time/iter: 26.86s | ETA: 00:30:53\n",
      "Image 132/200 (3642) | Time/iter: 10.19s | ETA: 00:11:33\n",
      "Image 133/200 (3679) | Time/iter: 18.66s | ETA: 00:20:50\n",
      "Image 134/200 (3701) | Time/iter: 13.24s | ETA: 00:14:34\n",
      "Image 135/200 (3715) | Time/iter: 23.18s | ETA: 00:25:06\n",
      "Image 136/200 (3730) | Time/iter: 8.89s | ETA: 00:09:28\n",
      "Image 137/200 (3773) | Time/iter: 8.09s | ETA: 00:08:29\n",
      "Image 138/200 (3859) | Time/iter: 22.95s | ETA: 00:23:42\n",
      "Image 139/200 (3864) | Time/iter: 22.83s | ETA: 00:23:12\n",
      "Image 140/200 (3877) | Time/iter: 22.92s | ETA: 00:22:55\n",
      "Image 141/200 (3916) | Time/iter: 22.92s | ETA: 00:22:32\n",
      "Image 142/200 (3932) | Time/iter: 18.40s | ETA: 00:17:47\n",
      "Image 143/200 (3958) | Time/iter: 13.44s | ETA: 00:12:45\n",
      "Image 144/200 (4023) | Time/iter: 23.07s | ETA: 00:21:31\n",
      "Image 145/200 (4032) | Time/iter: 13.05s | ETA: 00:11:57\n",
      "Image 146/200 (4037) | Time/iter: 9.00s | ETA: 00:08:06\n",
      "Image 147/200 (4057) | Time/iter: 22.63s | ETA: 00:19:59\n",
      "Image 148/200 (4131) | Time/iter: 9.01s | ETA: 00:07:48\n",
      "Image 149/200 (4136) | Time/iter: 22.88s | ETA: 00:19:26\n",
      "Image 150/200 (4203) | Time/iter: 14.61s | ETA: 00:12:10\n",
      "Image 151/200 (4217) | Time/iter: 18.04s | ETA: 00:14:43\n",
      "Image 152/200 (4259) | Time/iter: 26.81s | ETA: 00:21:26\n",
      "Image 153/200 (4264) | Time/iter: 23.10s | ETA: 00:18:05\n",
      "Image 154/200 (4269) | Time/iter: 23.28s | ETA: 00:17:51\n",
      "Image 155/200 (4287) | Time/iter: 8.79s | ETA: 00:06:35\n",
      "Image 156/200 (4302) | Time/iter: 18.22s | ETA: 00:13:21\n",
      "Image 157/200 (4392) | Time/iter: 13.09s | ETA: 00:09:23\n",
      "Image 158/200 (4440) | Time/iter: 13.09s | ETA: 00:09:09\n",
      "Image 159/200 (4495) | Time/iter: 32.73s | ETA: 00:22:21\n",
      "Image 160/200 (4496) | Time/iter: 22.89s | ETA: 00:15:15\n",
      "Image 161/200 (4542) | Time/iter: 12.88s | ETA: 00:08:22\n",
      "Image 162/200 (4574) | Time/iter: 18.32s | ETA: 00:11:36\n",
      "Image 163/200 (4593) | Time/iter: 22.77s | ETA: 00:14:02\n",
      "Image 164/200 (4627) | Time/iter: 12.94s | ETA: 00:07:45\n",
      "Image 165/200 (4687) | Time/iter: 25.60s | ETA: 00:14:55\n",
      "Image 166/200 (4746) | Time/iter: 6.50s | ETA: 00:03:40\n",
      "Image 167/200 (4767) | Time/iter: 17.81s | ETA: 00:09:47\n",
      "Image 168/200 (4788) | Time/iter: 26.68s | ETA: 00:14:13\n",
      "Image 169/200 (4796) | Time/iter: 8.71s | ETA: 00:04:30\n",
      "Image 170/200 (4823) | Time/iter: 22.85s | ETA: 00:11:25\n",
      "Image 171/200 (4825) | Time/iter: 9.10s | ETA: 00:04:23\n",
      "Image 172/200 (4856) | Time/iter: 22.83s | ETA: 00:10:39\n",
      "Image 173/200 (4934) | Time/iter: 18.00s | ETA: 00:08:05\n",
      "Image 174/200 (4991) | Time/iter: 9.88s | ETA: 00:04:16\n",
      "Image 175/200 (5049) | Time/iter: 9.63s | ETA: 00:04:00\n",
      "Image 176/200 (5059) | Time/iter: 22.94s | ETA: 00:09:10\n",
      "Image 177/200 (5062) | Time/iter: 22.88s | ETA: 00:08:46\n",
      "Image 178/200 (5214) | Time/iter: 22.88s | ETA: 00:08:23\n",
      "Image 179/200 (5234) | Time/iter: 8.63s | ETA: 00:03:01\n",
      "Image 180/200 (5249) | Time/iter: 22.70s | ETA: 00:07:33\n",
      "Image 181/200 (5253) | Time/iter: 13.48s | ETA: 00:04:16\n",
      "Image 182/200 (5254) | Time/iter: 18.41s | ETA: 00:05:31\n",
      "Image 183/200 (5285) | Time/iter: 7.72s | ETA: 00:02:11\n",
      "Image 184/200 (5360) | Time/iter: 3.95s | ETA: 00:01:03\n",
      "Image 185/200 (5382) | Time/iter: 19.29s | ETA: 00:04:49\n",
      "Image 186/200 (5383) | Time/iter: 23.11s | ETA: 00:05:23\n",
      "Image 187/200 (5460) | Time/iter: 17.99s | ETA: 00:03:53\n",
      "Image 188/200 (5568) | Time/iter: 20.69s | ETA: 00:04:08\n",
      "Image 189/200 (5589) | Time/iter: 18.24s | ETA: 00:03:20\n",
      "Image 190/200 (5593) | Time/iter: 12.58s | ETA: 00:02:05\n",
      "Image 191/200 (5611) | Time/iter: 20.53s | ETA: 00:03:04\n",
      "Image 192/200 (5617) | Time/iter: 9.85s | ETA: 00:01:18\n",
      "Image 193/200 (5652) | Time/iter: 18.17s | ETA: 00:02:07\n",
      "Image 194/200 (5668) | Time/iter: 10.01s | ETA: 00:01:00\n",
      "Image 195/200 (5673) | Time/iter: 10.22s | ETA: 00:00:51\n",
      "Image 196/200 (5693) | Time/iter: 6.87s | ETA: 00:00:27\n",
      "Image 197/200 (5695) | Time/iter: 7.35s | ETA: 00:00:22\n",
      "Image 198/200 (5698) | Time/iter: 15.83s | ETA: 00:00:31\n",
      "Image 199/200 (5708) | Time/iter: 21.37s | ETA: 00:00:21\n",
      "Image 200/200 (5721) | Time/iter: 18.06s | ETA: 00:00:00\n",
      "ðŸŽ‰ IIW reflectance outputs saved in: E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\detail_enhance_5_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "# IIW Dataset paths\n",
    "iiw_input_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\detail_enhance_5_input\"\n",
    "iiw_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\detail_enhance_5_output\"\n",
    "os.makedirs(iiw_output_dir, exist_ok=True)\n",
    "\n",
    "# --- Prevent accidental concurrent double-run (which duplicates output lines) ---\n",
    "if globals().get('_IIW_PROCESSING_ACTIVE', False):\n",
    "    raise RuntimeError(\"IIW processing already running in this kernel. Wait for it to finish or restart kernel.\")\n",
    "_IIW_PROCESSING_ACTIVE = True\n",
    "\n",
    "# --- Ensure dependencies from previous cell are available after a restart ---\n",
    "import sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "try:\n",
    "    load_image\n",
    "except NameError:\n",
    "    from chrislib.data_util import load_image  # Will raise if unavailable\n",
    "try:\n",
    "    view\n",
    "except NameError:\n",
    "    from chrislib.general import view, invert\n",
    "try:\n",
    "    run_pipeline\n",
    "except NameError:\n",
    "    from intrinsic.pipeline import run_pipeline\n",
    "if 'models' not in globals():\n",
    "    _IIW_PROCESSING_ACTIVE = False\n",
    "    raise RuntimeError(\"'models' dict missing. Execute the model loading cell above.\")\n",
    "if 'device' not in globals():\n",
    "    import torch\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def numeric_sort_key(path):\n",
    "    \"\"\"Return (leading_number, lowercase_name) for consistent numeric ordering.\"\"\"\n",
    "    fname = os.path.splitext(os.path.basename(path))[0]\n",
    "    m = re.match(r'^(\\d+)', fname)\n",
    "    if m:\n",
    "        return (int(m.group(1)), fname.lower())\n",
    "    return (float('inf'), fname.lower())\n",
    "\n",
    "# Collect images once (case-insensitive filtering) using os.listdir to avoid duplicate glob matches\n",
    "image_files = []\n",
    "for f in os.listdir(iiw_input_dir):\n",
    "    fl = f.lower()\n",
    "    if fl.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_files.append(os.path.join(iiw_input_dir, f))\n",
    "\n",
    "# Sort and take only the first N images\n",
    "iiw_image_paths = sorted(image_files, key=numeric_sort_key)\n",
    "MAX_TO_PROCESS = 1000\n",
    "batch_paths = iiw_image_paths[:MAX_TO_PROCESS]\n",
    "\n",
    "print(f\"Found {len(iiw_image_paths)} images in {iiw_input_dir}\")\n",
    "print(f\"Processing first {len(batch_paths)} images in numeric order\")\n",
    "if batch_paths:\n",
    "    preview = [os.path.splitext(os.path.basename(p))[0] for p in batch_paths[:15]]\n",
    "    print(\"Numeric processing order preview (first 15):\", preview)\n",
    "\n",
    "total_images = len(batch_paths)\n",
    "start_time = time.time()\n",
    "for idx, img_path in enumerate(batch_paths, 1):\n",
    "    iter_start = time.time()\n",
    "    image = load_image(img_path)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "    alb = view(results[\"hr_alb\"])\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(iiw_output_dir, f\"{fname}_reflectance.png\")\n",
    "    imwrite(out_path, alb_save)\n",
    "    iter_time = time.time() - iter_start\n",
    "    remaining = (total_images - idx) * iter_time\n",
    "    eta = time.strftime('%H:%M:%S', time.gmtime(max(0, remaining)))\n",
    "    print(f\"Image {idx}/{total_images} ({fname}) | Time/iter: {iter_time:.2f}s | ETA: {eta}\")\n",
    "\n",
    "print(f\"ðŸŽ‰ IIW reflectance outputs saved in: {iiw_output_dir}\")\n",
    "_IIW_PROCESSING_ACTIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47310ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images in E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [04:12<00:00, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Done! Outputs saved in:\n",
      "  Albedo â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_output\\albedo\n",
      "  Shading â†’ E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_output\\shading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "# Path to your Synthetic Dense dataset input images\n",
    "input_dir = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_input\"\n",
    "\n",
    "# Output directories for predicted intrinsic components\n",
    "output_root = \"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_output\"\n",
    "alb_dir = os.path.join(output_root, \"albedo\")\n",
    "shd_dir = os.path.join(output_root, \"shading\")\n",
    "os.makedirs(alb_dir, exist_ok=True)\n",
    "os.makedirs(shd_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# GET LIST OF INPUT IMAGES\n",
    "# -----------------------------\n",
    "image_paths = sorted(glob.glob(os.path.join(input_dir, \"*.png\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpg\")) +\n",
    "                     glob.glob(os.path.join(input_dir, \"*.jpeg\")))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in {input_dir}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PROCESS IMAGES\n",
    "# -----------------------------\n",
    "for img_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    # Load image\n",
    "    image = load_image(img_path)\n",
    "    # Ensure image is RGB (3 channels)\n",
    "    if image.ndim == 3 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "\n",
    "    # Run pipeline\n",
    "    results = run_pipeline(models, image, device=device)\n",
    "\n",
    "    # Get outputs\n",
    "    alb = view(results[\"hr_alb\"])         # gamma-corrected albedo\n",
    "    shd = 1 - invert(results[\"dif_shd\"])  # tonemapped diffuse shading\n",
    "\n",
    "    # File name without extension\n",
    "    fname = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    # Save albedo and shading separately\n",
    "    alb_save = (alb * 255).astype(np.uint8)\n",
    "    shd_save = (shd * 255).astype(np.uint8)\n",
    "\n",
    "    from imageio import imwrite\n",
    "    imwrite(os.path.join(alb_dir, f\"{fname}_alb.png\"), alb_save)\n",
    "    imwrite(os.path.join(shd_dir, f\"{fname}_shd.png\"), shd_save)\n",
    "\n",
    "print(f\"ðŸŽ‰ Done! Outputs saved in:\\n  Albedo â†’ {alb_dir}\\n  Shading â†’ {shd_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d409b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_2504\\2812710562.py:54: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_2504\\2812710562.py:55: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARAP Albedo: LMSE=0.1018, RMSE=0.2888, SSIM=0.5114\n",
      "ARAP Shading: LMSE=0.0892, RMSE=0.2507, SSIM=0.5555\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ARAP paths (use raw strings to avoid escape issues)\n",
    "arap_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_output\\albedo\"\n",
    "arap_pred_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\detail_enhance_5_output\\shading\"\n",
    "arap_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Albedo\"\n",
    "arap_gt_shading_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\ARAP Dataset\\Gt_Shading\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    # Drop alpha if present, then convert to grayscale and squeeze to 2D\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    # Ensure odd window <= min(h, w); fallback to 3 if needed\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3:\n",
    "        win = 3\n",
    "    if win % 2 == 0:\n",
    "        win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def compute_metrics(pred_dir, gt_dir, metric_type):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if metric_type == 'alb' and (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            base_name = fname.rsplit('_alb', 1)[0]\n",
    "            gt_suffix = '_albedo'\n",
    "        elif metric_type == 'shd' and (low.endswith('_shd.png') or low.endswith('_shd.jpg') or low.endswith('_shd.jpeg')):\n",
    "            base_name = fname.rsplit('_shd', 1)[0]\n",
    "            gt_suffix = '_shading'\n",
    "        else:\n",
    "            print(f\"Skipping {fname} (unexpected suffix)\")\n",
    "            continue\n",
    "        gt_file = None\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            candidate = f\"{base_name}{gt_suffix}{ext}\"\n",
    "            if os.path.exists(os.path.join(gt_dir, candidate)):\n",
    "                gt_file = candidate\n",
    "                break\n",
    "        if gt_file is None:\n",
    "            print(f\"No GT found for {fname}\")\n",
    "            continue\n",
    "        pred_img = imread(os.path.join(pred_dir, fname)).astype(np.float32) / 255.0\n",
    "        gt_img = imread(os.path.join(gt_dir, gt_file)).astype(np.float32) / 255.0\n",
    "        # Grayscale first, strictly 2D\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        # Resize only grayscale to match shapes\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        # LMSE implementation on grayscale\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                # If image too small for one window, fallback to global MSE\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gt_patch = gt[i:i+window_size, j:j+window_size]\n",
    "                    pred_patch = pred[i:i+window_size, j:j+window_size]\n",
    "                    mse = np.mean((gt_patch - pred_patch) ** 2)\n",
    "                    errors.append(mse)\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_val = lmse(gt_gray, pred_gray, window_size=20, window_shift=10)\n",
    "        rmse_val = float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2)))\n",
    "        ssim_val = float(safe_ssim(pred_gray, gt_gray))\n",
    "        lmse_vals.append(lmse_val)\n",
    "        rmse_vals.append(rmse_val)\n",
    "        ssim_vals.append(ssim_val)\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "# Compute metrics for albedo\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_metrics(arap_pred_albedo_dir, arap_gt_albedo_dir, metric_type='alb')\n",
    "print(f\"ARAP Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")\n",
    "\n",
    "# Compute metrics for shading\n",
    "lmse_shd, rmse_shd, ssim_shd = compute_metrics(arap_pred_shading_dir, arap_gt_shading_dir, metric_type='shd')\n",
    "print(f\"ARAP Shading: LMSE={lmse_shd:.4f}, RMSE={rmse_shd:.4f}, SSIM={ssim_shd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a5d874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014: WHDR=0.6233\n",
      "1068: WHDR=0.5213\n",
      "1094: WHDR=0.1633\n",
      "1118: WHDR=0.5796\n",
      "1127: WHDR=0.2848\n",
      "1141: WHDR=0.4826\n",
      "1143: WHDR=0.4496\n",
      "116: WHDR=0.2388\n",
      "1195: WHDR=0.4386\n",
      "119: WHDR=0.7563\n",
      "1206: WHDR=0.5225\n",
      "1221: WHDR=0.5104\n",
      "1226: WHDR=0.7265\n",
      "1232: WHDR=0.5679\n",
      "1245: WHDR=0.5394\n",
      "1302: WHDR=0.2316\n",
      "1376: WHDR=0.4934\n",
      "141: WHDR=0.5062\n",
      "1453: WHDR=0.2954\n",
      "1694: WHDR=0.1813\n",
      "176: WHDR=0.6008\n",
      "180: WHDR=0.5994\n",
      "182: WHDR=0.3021\n",
      "1934: WHDR=0.1121\n",
      "2066: WHDR=0.2691\n",
      "2200: WHDR=0.1759\n",
      "2232: WHDR=0.6950\n",
      "2237: WHDR=0.4308\n",
      "2254: WHDR=0.4664\n",
      "227: WHDR=0.3728\n",
      "2301: WHDR=0.4859\n",
      "2305: WHDR=0.6679\n",
      "2311: WHDR=0.4262\n",
      "2324: WHDR=0.6352\n",
      "2349: WHDR=0.4679\n",
      "2352: WHDR=0.3849\n",
      "2355: WHDR=0.6863\n",
      "2377: WHDR=0.4896\n",
      "239: WHDR=0.5262\n",
      "2406: WHDR=0.3359\n",
      "245: WHDR=0.4434\n",
      "2466: WHDR=0.6589\n",
      "2471: WHDR=0.6080\n",
      "2476: WHDR=0.4399\n",
      "2504: WHDR=0.4441\n",
      "253: WHDR=0.7246\n",
      "2545: WHDR=0.5305\n",
      "2547: WHDR=0.5102\n",
      "2548: WHDR=0.4410\n",
      "257: WHDR=0.6485\n",
      "2598: WHDR=0.5952\n",
      "2602: WHDR=0.5565\n",
      "2606: WHDR=0.2877\n",
      "2615: WHDR=0.3135\n",
      "2620: WHDR=0.4942\n",
      "262: WHDR=0.6007\n",
      "2636: WHDR=0.4413\n",
      "2715: WHDR=0.3349\n",
      "2727: WHDR=0.6467\n",
      "2758: WHDR=0.5606\n",
      "277: WHDR=0.5080\n",
      "2789: WHDR=0.7654\n",
      "2828: WHDR=0.4311\n",
      "2894: WHDR=0.5945\n",
      "2910: WHDR=0.5440\n",
      "2970: WHDR=0.4804\n",
      "2998: WHDR=0.5759\n",
      "3044: WHDR=0.4688\n",
      "3072: WHDR=0.5909\n",
      "3136: WHDR=0.6775\n",
      "3199: WHDR=0.4979\n",
      "3219: WHDR=0.3978\n",
      "3221: WHDR=0.8018\n",
      "3240: WHDR=0.5937\n",
      "3246: WHDR=0.4747\n",
      "3247: WHDR=0.3484\n",
      "3254: WHDR=0.4289\n",
      "3305: WHDR=0.5427\n",
      "3308: WHDR=0.2308\n",
      "3353: WHDR=0.3467\n",
      "3363: WHDR=0.4558\n",
      "3392: WHDR=0.5124\n",
      "3400: WHDR=0.2818\n",
      "3403: WHDR=0.5059\n",
      "3438: WHDR=0.3902\n",
      "3446: WHDR=0.6175\n",
      "3463: WHDR=0.4652\n",
      "3466: WHDR=0.3957\n",
      "3544: WHDR=0.5729\n",
      "3592: WHDR=0.4663\n",
      "3625: WHDR=0.4860\n",
      "3642: WHDR=0.3828\n",
      "3679: WHDR=0.2478\n",
      "3701: WHDR=0.5879\n",
      "370: WHDR=0.5575\n",
      "3715: WHDR=0.3756\n",
      "3730: WHDR=0.3790\n",
      "3773: WHDR=0.6366\n",
      "3859: WHDR=0.4754\n",
      "3864: WHDR=0.4763\n",
      "3877: WHDR=0.3163\n",
      "3916: WHDR=0.6860\n",
      "3932: WHDR=0.3124\n",
      "3958: WHDR=0.5657\n",
      "4023: WHDR=0.3224\n",
      "4032: WHDR=0.2894\n",
      "4037: WHDR=0.6744\n",
      "4057: WHDR=0.4290\n",
      "4131: WHDR=0.4702\n",
      "4136: WHDR=0.5848\n",
      "417: WHDR=0.3335\n",
      "4203: WHDR=0.4871\n",
      "4217: WHDR=0.5676\n",
      "4259: WHDR=0.7354\n",
      "4264: WHDR=0.3826\n",
      "4269: WHDR=0.3970\n",
      "4287: WHDR=0.6430\n",
      "4302: WHDR=0.6132\n",
      "434: WHDR=0.4010\n",
      "4392: WHDR=0.6682\n",
      "4440: WHDR=0.4460\n",
      "4495: WHDR=0.6245\n",
      "4496: WHDR=0.4700\n",
      "4542: WHDR=0.2194\n",
      "4574: WHDR=0.4089\n",
      "4593: WHDR=0.4640\n",
      "4627: WHDR=0.2222\n",
      "4687: WHDR=0.5818\n",
      "4746: WHDR=0.3723\n",
      "4767: WHDR=0.7890\n",
      "4788: WHDR=0.6044\n",
      "4796: WHDR=0.4607\n",
      "4823: WHDR=0.5001\n",
      "4825: WHDR=0.4311\n",
      "4856: WHDR=0.4620\n",
      "491: WHDR=0.4904\n",
      "4934: WHDR=0.5663\n",
      "498: WHDR=0.4664\n",
      "4991: WHDR=0.3588\n",
      "502: WHDR=0.1770\n",
      "5049: WHDR=0.3331\n",
      "504: WHDR=0.4956\n",
      "5059: WHDR=0.4281\n",
      "5062: WHDR=0.6125\n",
      "5214: WHDR=0.4292\n",
      "5234: WHDR=0.5673\n",
      "5249: WHDR=0.7044\n",
      "5253: WHDR=0.6155\n",
      "5254: WHDR=0.4346\n",
      "527: WHDR=0.3268\n",
      "5285: WHDR=0.5771\n",
      "5360: WHDR=0.3718\n",
      "5382: WHDR=0.4187\n",
      "5383: WHDR=0.5469\n",
      "5460: WHDR=0.6090\n",
      "54: WHDR=0.3261\n",
      "5568: WHDR=0.5215\n",
      "5589: WHDR=0.6552\n",
      "5593: WHDR=0.8114\n",
      "560: WHDR=0.5645\n",
      "5611: WHDR=0.4499\n",
      "5617: WHDR=0.4397\n",
      "5652: WHDR=0.7000\n",
      "5668: WHDR=0.1228\n",
      "5673: WHDR=0.7379\n",
      "5693: WHDR=0.3440\n",
      "5695: WHDR=0.9578\n",
      "5698: WHDR=0.5095\n",
      "5708: WHDR=0.4443\n",
      "5721: WHDR=0.5583\n",
      "579: WHDR=0.4806\n",
      "593: WHDR=0.5767\n",
      "594: WHDR=0.5199\n",
      "597: WHDR=0.4530\n",
      "611: WHDR=0.6246\n",
      "613: WHDR=0.5983\n",
      "627: WHDR=0.2525\n",
      "633: WHDR=0.4991\n",
      "63: WHDR=0.4220\n",
      "653: WHDR=0.3725\n",
      "657: WHDR=0.0000\n",
      "662: WHDR=0.5243\n",
      "686: WHDR=0.7053\n",
      "749: WHDR=0.4891\n",
      "760: WHDR=0.4416\n",
      "771: WHDR=0.4527\n",
      "791: WHDR=0.5050\n",
      "815: WHDR=0.4639\n",
      "821: WHDR=0.6473\n",
      "827: WHDR=0.2758\n",
      "844: WHDR=0.6077\n",
      "845: WHDR=0.3912\n",
      "856: WHDR=0.2463\n",
      "859: WHDR=0.2945\n",
      "860: WHDR=0.3462\n",
      "876: WHDR=0.4330\n",
      "918: WHDR=0.5016\n",
      "922: WHDR=0.4728\n",
      "952: WHDR=0.5041\n",
      "953: WHDR=0.4227\n",
      "\n",
      "Evaluated 200 images. Mean WHDR = 0.4811\n"
     ]
    }
   ],
   "source": [
    "# Compute WHDR for IIW outputs using attached whdr logic (Python 3 safe)\n",
    "import os, json, sys\n",
    "sys.path.insert(0, \"imports\")\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Paths (raw strings for Windows)\n",
    "iiW_output_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\detail_enhance_5_output\"\n",
    "iiW_annotations_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\IIW Dataset\\data\\annotations\"\n",
    "\n",
    "# --- WHDR utilities (ported to Py3, in-notebook) ---\n",
    "def srgb_to_rgb(srgb):\n",
    "    srgb = np.asarray(srgb, dtype=np.float32)\n",
    "    ret = np.zeros_like(srgb, dtype=np.float32)\n",
    "    idx0 = srgb <= 0.04045\n",
    "    idx1 = ~idx0\n",
    "    ret[idx0] = srgb[idx0] / 12.92\n",
    "    ret[idx1] = np.power((srgb[idx1] + 0.055) / 1.055, 2.4)\n",
    "    return ret\n",
    "\n",
    "def load_image_linear(filename, is_srgb=True):\n",
    "    if not filename:\n",
    "        raise ValueError(\"Empty filename\")\n",
    "    image = np.asarray(Image.open(filename)).astype(np.float32) / 255.0\n",
    "    if is_srgb:\n",
    "        return srgb_to_rgb(image)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def compute_whdr(reflectance, judgements, delta=0.10):\n",
    "    points = judgements['intrinsic_points']\n",
    "    comparisons = judgements['intrinsic_comparisons']\n",
    "    id_to_points = {p['id']: p for p in points}\n",
    "    rows, cols = reflectance.shape[0:2]\n",
    "\n",
    "    error_sum = 0.0\n",
    "    weight_sum = 0.0\n",
    "\n",
    "    for c in comparisons:\n",
    "        darker = c.get('darker')\n",
    "        if darker not in ('1', '2', 'E'):\n",
    "            continue\n",
    "\n",
    "        weight = c.get('darker_score')\n",
    "        if weight is None or weight <= 0:\n",
    "            continue\n",
    "\n",
    "        p1 = id_to_points.get(c['point1'])\n",
    "        p2 = id_to_points.get(c['point2'])\n",
    "        if p1 is None or p2 is None:\n",
    "            continue\n",
    "        if not p1.get('opaque', False) or not p2.get('opaque', False):\n",
    "            continue\n",
    "\n",
    "        y1 = min(rows - 1, max(0, int(p1['y'] * rows)))\n",
    "        x1 = min(cols - 1, max(0, int(p1['x'] * cols)))\n",
    "        y2 = min(rows - 1, max(0, int(p2['y'] * rows)))\n",
    "        x2 = min(cols - 1, max(0, int(p2['x'] * cols)))\n",
    "\n",
    "        l1 = max(1e-10, float(np.mean(reflectance[y1, x1, ...])))\n",
    "        l2 = max(1e-10, float(np.mean(reflectance[y2, x2, ...])))\n",
    "\n",
    "        if l2 / l1 > 1.0 + delta:\n",
    "            alg_darker = '1'\n",
    "        elif l1 / l2 > 1.0 + delta:\n",
    "            alg_darker = '2'\n",
    "        else:\n",
    "            alg_darker = 'E'\n",
    "\n",
    "        if darker != alg_darker:\n",
    "            error_sum += weight\n",
    "        weight_sum += weight\n",
    "\n",
    "    if weight_sum > 0:\n",
    "        return error_sum / weight_sum\n",
    "    return None\n",
    "\n",
    "# --- Batch evaluation over available outputs ---\n",
    "# We only evaluate files present in the output directory; we expect names like 1014_reflectance.png\n",
    "valid_exts = ('.png', '.jpg', '.jpeg')\n",
    "reflectance_files = [f for f in os.listdir(iiW_output_dir) if f.lower().endswith(valid_exts) and '_reflectance' in f]\n",
    "reflectance_files.sort()\n",
    "\n",
    "results = []\n",
    "for f in reflectance_files:\n",
    "    stem = os.path.splitext(f)[0]\n",
    "    # Expect pattern <photoid>_reflectance\n",
    "    if not stem.endswith('_reflectance'):\n",
    "        continue\n",
    "    photo_id = stem.rsplit('_reflectance', 1)[0]\n",
    "    json_path = os.path.join(iiW_annotations_dir, f\"{photo_id}.json\")\n",
    "    img_path = os.path.join(iiW_output_dir, f)\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Skipping {f}: missing annotations {photo_id}.json\")\n",
    "        continue\n",
    "    try:\n",
    "        refl = load_image_linear(img_path, is_srgb=True)  # saved PNGs are sRGB; convert to linear\n",
    "        with open(json_path, 'r') as jf:\n",
    "            judg = json.load(jf)\n",
    "        score = compute_whdr(refl, judg, delta=0.10)\n",
    "        if score is None:\n",
    "            print(f\"{photo_id}: no valid judgements; WHDR=None\")\n",
    "            continue\n",
    "        results.append((photo_id, score))\n",
    "        print(f\"{photo_id}: WHDR={score:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{photo_id}: error computing WHDR -> {e}\")\n",
    "\n",
    "if results:\n",
    "    mean_whdr = float(np.mean([s for _, s in results]))\n",
    "    print(f\"\\nEvaluated {len(results)} images. Mean WHDR = {mean_whdr:.4f}\")\n",
    "else:\n",
    "    print(\"No WHDR scores computed. Ensure output images and matching JSONs exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b1cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_2504\\2392862376.py:61: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
      "C:\\Users\\Arnav Jalan\\AppData\\Local\\Temp\\ipykernel_2504\\2392862376.py:62: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  gt_img = imread(gt_path).astype(np.float32) / 255.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 22 pairs; Missing GT for 1 files.\n",
      "Synthetic Dense Albedo: LMSE=0.0579, RMSE=0.2345, SSIM=0.4757\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Dense Albedo Metrics Only (LMSE, RMSE, SSIM) with robust GT matching\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Synthetic Dense paths (update if your dataset root differs)\n",
    "sd_pred_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\detail_enhance_5_output\\albedo\"\n",
    "sd_gt_albedo_dir = r\"E:\\COLLEGE MATERIAL\\Ordinal_Shading\\Synthetic Dense Dataset(Sentinel)\\Gt_albedo\"\n",
    "\n",
    "def to_gray_strict(arr):\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]\n",
    "    if arr.ndim == 3 and arr.shape[2] == 3:\n",
    "        arr = np.mean(arr, axis=2)\n",
    "    return np.squeeze(arr)\n",
    "\n",
    "def safe_ssim(a, b):\n",
    "    h, w = b.shape\n",
    "    win = min(7, h, w)\n",
    "    if win < 3: win = 3\n",
    "    if win % 2 == 0: win -= 1\n",
    "    return ssim(a, b, data_range=1.0, win_size=win)\n",
    "\n",
    "def find_gt_file(gt_dir: str, stem: str):\n",
    "    candidates = []\n",
    "    # Common direct patterns\n",
    "    for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "        candidates.append(f\"{stem}_albedo{ext}\")\n",
    "        candidates.append(f\"{stem}{ext}\")\n",
    "    for c in candidates:\n",
    "        p = os.path.join(gt_dir, c)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    # Fallback: scan directory for files that start with stem and contain 'alb' or 'albedo'\n",
    "    low_stem = stem.lower()\n",
    "    for f in os.listdir(gt_dir):\n",
    "        fl = f.lower()\n",
    "        if (fl.startswith(low_stem)) and (('albedo' in fl) or ('alb' in fl)) and fl.endswith(tuple(['.png','.jpg','.jpeg','.PNG','.JPG','.JPEG'])):\n",
    "            return os.path.join(gt_dir, f)\n",
    "    return None\n",
    "\n",
    "def compute_albedo_metrics(pred_dir, gt_dir):\n",
    "    lmse_vals, rmse_vals, ssim_vals = [], [], []\n",
    "    pred_files = sorted([f for f in os.listdir(pred_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    if not pred_files:\n",
    "        print(f\"âš  No predicted albedo files found in {pred_dir}\")\n",
    "        return None, None, None\n",
    "    matched = 0; missing = 0\n",
    "    for fname in pred_files:\n",
    "        low = fname.lower()\n",
    "        if not (low.endswith('_alb.png') or low.endswith('_alb.jpg') or low.endswith('_alb.jpeg')):\n",
    "            continue\n",
    "        stem = fname.rsplit('_alb', 1)[0]\n",
    "        gt_path = find_gt_file(gt_dir, stem)\n",
    "        if gt_path is None:\n",
    "            missing += 1\n",
    "            continue\n",
    "        pred_path = os.path.join(pred_dir, fname)\n",
    "        pred_img = imread(pred_path).astype(np.float32) / 255.0\n",
    "        gt_img = imread(gt_path).astype(np.float32) / 255.0\n",
    "        pred_gray = to_gray_strict(pred_img)\n",
    "        gt_gray = to_gray_strict(gt_img)\n",
    "        if pred_gray.shape != gt_gray.shape:\n",
    "            pred_gray = resize(pred_gray, gt_gray.shape, order=1, preserve_range=True, anti_aliasing=True)\n",
    "        def lmse(gt, pred, window_size=20, window_shift=10):\n",
    "            h, w = gt.shape\n",
    "            if h < window_size or w < window_size:\n",
    "                return float(np.mean((gt - pred) ** 2))\n",
    "            errors = []\n",
    "            for i in range(0, h - window_size + 1, window_shift):\n",
    "                for j in range(0, w - window_size + 1, window_shift):\n",
    "                    gpatch = gt[i:i+window_size, j:j+window_size]\n",
    "                    ppatch = pred[i:i+window_size, j:j+window_size]\n",
    "                    errors.append(np.mean((gpatch - ppatch) ** 2))\n",
    "            return float(np.mean(errors)) if errors else float('nan')\n",
    "        lmse_vals.append(lmse(gt_gray, pred_gray))\n",
    "        rmse_vals.append(float(np.sqrt(np.mean((pred_gray - gt_gray) ** 2))))\n",
    "        ssim_vals.append(float(safe_ssim(pred_gray, gt_gray)))\n",
    "        matched += 1\n",
    "    if matched == 0:\n",
    "        print(f\"âš  No GT matches found in {gt_dir} for stems of predictions in {pred_dir}. Check naming.\")\n",
    "        if missing > 0:\n",
    "            print(f\"   Missing GT for {missing} predicted files.\")\n",
    "        return None, None, None\n",
    "    print(f\"Matched {matched} pairs; Missing GT for {missing} files.\")\n",
    "    return float(np.nanmean(lmse_vals)), float(np.nanmean(rmse_vals)), float(np.nanmean(ssim_vals))\n",
    "\n",
    "lmse_alb, rmse_alb, ssim_alb = compute_albedo_metrics(sd_pred_albedo_dir, sd_gt_albedo_dir)\n",
    "if lmse_alb is None:\n",
    "    print(\"Synthetic Dense Albedo: metrics unavailable (no matched pairs).\")\n",
    "else:\n",
    "    print(f\"Synthetic Dense Albedo: LMSE={lmse_alb:.4f}, RMSE={rmse_alb:.4f}, SSIM={ssim_alb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
